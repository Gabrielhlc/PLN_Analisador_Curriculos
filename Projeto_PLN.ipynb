{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "wm8DOHDw-Qsv",
        "Wf-4Zx14_YWs"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Gabrielhlc/PLN_Analisador_Curriculos/blob/main/Projeto_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Instalações e Bibliotecas"
      ],
      "metadata": {
        "id": "wm8DOHDw-Qsv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "ckH9o29f0-Hu",
        "outputId": "4dc67782-280e-463d-838f-8d5530bbf7b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docling\n",
            "  Downloading docling-2.53.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.11.7)\n",
            "Collecting docling-core<3.0.0,>=2.48.0 (from docling-core[chunking]<3.0.0,>=2.48.0->docling)\n",
            "  Downloading docling_core-2.48.1-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.4.0 (from docling)\n",
            "  Downloading docling_parse-4.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.8 kB)\n",
            "Collecting docling-ibm-models<4,>=3.9.1 (from docling)\n",
            "  Downloading docling_ibm_models-3.9.1-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting pypdfium2!=4.30.1,<5.0.0,>=4.30.0 (from docling)\n",
            "  Downloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/48.5 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic-settings<3.0.0,>=2.3.0 in /usr/local/lib/python3.12/dist-packages (from docling) (2.10.1)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /usr/local/lib/python3.12/dist-packages (from docling) (0.34.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from docling) (2.32.4)\n",
            "Collecting easyocr<2.0,>=1.7 (from docling)\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2025.8.3)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
            "  Downloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting typer<0.17.0,>=0.12.5 (from docling)\n",
            "  Downloading typer-0.16.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.2.0-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /usr/local/lib/python3.12/dist-packages (from docling) (4.13.5)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /usr/local/lib/python3.12/dist-packages (from docling) (2.2.2)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.2.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: openpyxl<4.0.0,>=3.1.5 in /usr/local/lib/python3.12/dist-packages (from docling) (3.1.5)\n",
            "Requirement already satisfied: lxml<6.0.0,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (5.4.0)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (11.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /usr/local/lib/python3.12/dist-packages (from docling) (4.67.1)\n",
            "Requirement already satisfied: pluggy<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.6.0)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.16.1)\n",
            "Requirement already satisfied: accelerate<2,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from docling) (1.10.1)\n",
            "Collecting polyfactory>=2.22.2 (from docling)\n",
            "  Downloading polyfactory-2.22.2-py3-none-any.whl.metadata (27 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (25.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (6.0.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (2.8.0+cu126)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate<2,>=1.0.0->docling) (0.6.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (2.8)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.15.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (4.25.1)\n",
            "Collecting jsonref<2.0.0,>=1.1.0 (from docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling)\n",
            "  Downloading jsonref-1.1.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (0.9.0)\n",
            "Collecting latex2mathml<4.0.0,>=3.77.0 (from docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling)\n",
            "  Downloading latex2mathml-3.78.1-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.48.0->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.12/dist-packages (from docling-core[chunking]<3.0.0,>=2.48.0->docling) (4.56.1)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /usr/local/lib/python3.12/dist-packages (from docling-ibm-models<4,>=3.9.1->docling) (0.23.0+cu126)\n",
            "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4,>=3.9.1->docling)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: opencv-python-headless<5.0.0.0,>=4.6.0.66 in /usr/local/lib/python3.12/dist-packages (from docling-ibm-models<4,>=3.9.1->docling) (4.12.0.88)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.12/dist-packages (from easyocr<2.0,>=1.7->docling) (0.25.2)\n",
            "Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading python_bidi-0.6.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.12/dist-packages (from easyocr<2.0,>=1.7->docling) (2.1.1)\n",
            "Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub<1,>=0.23->docling) (1.1.9)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.12/dist-packages (from openpyxl<4.0.0,>=3.1.5->docling) (2.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Collecting faker>=5.0.0 (from polyfactory>=2.22.2->docling)\n",
            "  Downloading faker-37.8.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.3.0->docling) (1.1.1)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading xlsxwriter-3.2.9-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.2->docling) (2.5.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.17.0,>=0.12.5->docling) (8.2.1)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.17.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.12/dist-packages (from typer<0.17.0,>=0.12.5->docling) (13.9.4)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4,>=3.9.1->docling) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.48.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (0.27.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (2.19.2)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.0->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (0.22.0)\n",
            "Requirement already satisfied: imageio!=2.35.0,>=2.33 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2.37.0)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (2025.8.28)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.12/dist-packages (from scikit-image->easyocr<2.0,>=1.7->docling) (0.4)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.17.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate<2,>=1.0.0->docling) (3.0.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /usr/local/lib/python3.12/dist-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /usr/local/lib/python3.12/dist-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.48.0->docling) (0.3.8)\n",
            "Downloading docling-2.53.0-py3-none-any.whl (225 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.3/225.3 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_core-2.48.1-py3-none-any.whl (164 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m164.3/164.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.9.1-py3-none-any.whl (86 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.5.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.1/15.1 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m102.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading marko-2.2.0-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.7/42.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading polyfactory-2.22.2-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pypdfium2-4.30.0-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m49.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.2.0-py3-none-any.whl (252 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.0/253.0 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.1-py3-none-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.6/507.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typer-0.16.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.4/46.4 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading faker-37.8.0-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m82.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Downloading jsonref-1.1.0-py3-none-any.whl (9.4 kB)\n",
            "Downloading latex2mathml-3.78.1-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.9/73.9 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading xlsxwriter-3.2.9-py3-none-any.whl (175 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.3/175.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.13.0-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (180 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.7/180.7 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (963 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m963.8/963.8 kB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (292 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m292.1/292.1 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136817 sha256=7d3ba6a6c1b82033ab812f2b3e9d48b01891ad7f7126ba0d92d93ed8bf27e794\n",
            "  Stored in directory: /root/.cache/pip/wheels/06/3e/78/fa1588c1ae991bbfd814af2bcac6cef7a178beee1939180d46\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: python-bidi, pylatexenc, pyclipper, filetype, XlsxWriter, rtree, python-docx, pypdfium2, ninja, mpire, marko, latex2mathml, jsonref, jsonlines, faker, python-pptx, polyfactory, typer, semchunk, docling-core, easyocr, docling-parse, docling-ibm-models, docling\n",
            "  Attempting uninstall: typer\n",
            "    Found existing installation: typer 0.17.4\n",
            "    Uninstalling typer-0.17.4:\n",
            "      Successfully uninstalled typer-0.17.4\n",
            "Successfully installed XlsxWriter-3.2.9 docling-2.53.0 docling-core-2.48.1 docling-ibm-models-3.9.1 docling-parse-4.5.0 easyocr-1.7.2 faker-37.8.0 filetype-1.2.0 jsonlines-3.1.0 jsonref-1.1.0 latex2mathml-3.78.1 marko-2.2.0 mpire-2.10.2 ninja-1.13.0 polyfactory-2.22.2 pyclipper-1.3.0.post6 pylatexenc-2.10 pypdfium2-4.30.0 python-bidi-0.6.6 python-docx-1.2.0 python-pptx-1.0.2 rtree-1.4.1 semchunk-2.2.2 typer-0.16.1\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (0.2.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.34.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.9)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (0.3.27)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.29-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: sentence-transformers in /usr/local/lib/python3.12/dist-packages (5.1.0)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.75)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.3.11)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.12/dist-packages (from langchain) (0.4.27)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.0.43)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.32.4)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.12/dist-packages (from langchain) (6.0.2)\n",
            "Collecting requests<3,>=2 (from langchain)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.10.1)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.56.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.67.1)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (2.8.0+cu126)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (1.16.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.20.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (0.34.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (11.3.0)\n",
            "Requirement already satisfied: typing_extensions>=4.5.0 in /usr/local/lib/python3.12/dist-packages (from sentence-transformers) (4.15.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.19.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (25.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.20.0->sentence-transformers) (1.1.9)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.12/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.1.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.11.0->sentence-transformers) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.6.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.10.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
            "Downloading langchain_community-0.3.29-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m95.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-community-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install docling --no-warn-conflicts\n",
        "!pip install transformers sentencepiece\n",
        "!pip install langchain langchain-community sentence-transformers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalação local da LLM usada como motor de busca para o RAG (LLaMa)"
      ],
      "metadata": {
        "id": "MhxQOGULsGvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# inicia o servidor em background\n",
        "!nohup ollama serve > /dev/null 2>&1 &\n",
        "\n",
        "!ollama pull llama3.1:8b"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jk5gfGIIVcrR",
        "outputId": "7bbb9bb1-e5c8-45fa-b9a0-b5e91997bff4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "######################################################################## 100.0%\n",
            ">>> Creating ollama user...\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n",
            "\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[1G\u001b[?25h\u001b[?2026l\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Descompactação de Zip e Extração dos PDFs para markdown"
      ],
      "metadata": {
        "id": "IZV8Aft1-G5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Função de descompactação"
      ],
      "metadata": {
        "id": "xVCx254woW7f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "import shutil\n",
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "\n",
        "def processar_zip(zip_path=\"curriculos.zip\", output_folder=\"curriculosMD\"):\n",
        "    \"\"\"\n",
        "    Lê um zip com PDFs, converte cada PDF para markdown usando Docling, salva na pasta output_folder\n",
        "    e retorna um dicionário {nome_arquivo: conteúdo_markdown}.\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    converter = DocumentConverter()\n",
        "    curriculos_md = {}\n",
        "    cid_para_arquivo_map = {}\n",
        "\n",
        "\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        arquivos_pdf = [f for f in zip_ref.namelist() if not f.endswith(\"/\") and f.lower().endswith('.pdf')]\n",
        "\n",
        "        for idx, file_name in enumerate(arquivos_pdf):\n",
        "            cid = f\"curr_{idx}\"\n",
        "            original_filename = os.path.basename(file_name)\n",
        "            print(original_filename)\n",
        "            cid_para_arquivo_map[cid] = original_filename\n",
        "\n",
        "            if file_name.endswith(\"/\"):\n",
        "                continue\n",
        "\n",
        "            extracted_path = zip_ref.extract(file_name)\n",
        "            base_name = os.path.splitext(os.path.basename(file_name))[0]\n",
        "            md_path = os.path.join(output_folder, f\"{base_name}.md\")\n",
        "\n",
        "            try:\n",
        "                doc = converter.convert(extracted_path).document\n",
        "                markdown_content = doc.export_to_markdown()\n",
        "\n",
        "                # Salvar arquivo markdown\n",
        "                with open(md_path, 'w', encoding='utf-8') as md_file:\n",
        "                    md_file.write(markdown_content)\n",
        "\n",
        "                curriculos_md[base_name] = markdown_content\n",
        "            except Exception as e:\n",
        "                print(f\"Erro ao converter {file_name}: {e}\")\n",
        "\n",
        "            os.remove(extracted_path)\n",
        "\n",
        "    temp_dirs = [\"curriculos\", \"tmp\", \"temp\"]\n",
        "    for temp_dir in temp_dirs:\n",
        "        if os.path.exists(temp_dir):\n",
        "            shutil.rmtree(temp_dir)\n",
        "\n",
        "    print(f\"Todos os arquivos foram processados e salvos em '{output_folder}'.\")\n",
        "    return curriculos_md, cid_para_arquivo_map"
      ],
      "metadata": {
        "id": "_NljxhLT_HPo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execução da função de descompactação"
      ],
      "metadata": {
        "id": "Wf-4Zx14_YWs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"curriculos.zip\"\n",
        "curriculos, cid_arquivo_map = processar_zip(zip_path)\n",
        "\n",
        "print(f\"Total processados: {len(curriculos)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "5-vYmOU361zT",
        "outputId": "3229b0ed-c233-47c5-ed79-eb4249fe96e4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Débora Rocha.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "WARNING:easyocr.easyocr:Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ulisses Dias.pdf\n",
            "Talita Oliveira.pdf\n",
            "Íris Pinto.pdf\n",
            "Ulisses Melo.pdf\n",
            "Íris Vaz.pdf\n",
            "Júlia Moura.pdf\n",
            "Mônica Gomes.pdf\n",
            "Mônica Azevedo.pdf\n",
            "Vitor Gomes.pdf\n",
            "Mônica Rocha.pdf\n",
            "João Costa.pdf\n",
            "Amanda Silva.pdf\n",
            "Talita Araújo.pdf\n",
            "Vitor Machado.pdf\n",
            "Yasmin Freitas.pdf\n",
            "Wilson Ramos.pdf\n",
            "Patrícia Barros.pdf\n",
            "Otávio Azevedo.pdf\n",
            "Eduardo Sousa.pdf\n",
            "Otávio Silva.pdf\n",
            "Débora Dias.pdf\n",
            "Carlos Souza.pdf\n",
            "Bruno Carvalho.pdf\n",
            "Beatriz Costa.pdf\n",
            "Valentina Melo.pdf\n",
            "Júlia Brito.pdf\n",
            "Carlos Teixeira.pdf\n",
            "Eduardo Barbosa.pdf\n",
            "Íris Melo.pdf\n",
            "Carlos Gomes.pdf\n",
            "Daniela Rocha.pdf\n",
            "Carlos Machado.pdf\n",
            "Amanda Brito.pdf\n",
            "Patrícia Lima.pdf\n",
            "Carlos Araújo.pdf\n",
            "Otávio Moura.pdf\n",
            "Júlia Monteiro.pdf\n",
            "Valentina Freitas.pdf\n",
            "Thiago Araújo.pdf\n",
            "Fabiana Almeida.pdf\n",
            "João Brito.pdf\n",
            "Natália Ferreira.pdf\n",
            "Carlos Freitas.pdf\n",
            "Ulisses Barros.pdf\n",
            "Talita Nascimento.pdf\n",
            "Yasmin Ramos.pdf\n",
            "curriculo_1.pdf\n",
            "curriculo_10.pdf\n",
            "curriculo_11.pdf\n",
            "curriculo_12.pdf\n",
            "curriculo_13.pdf\n",
            "curriculo_14.pdf\n",
            "curriculo_2.pdf\n",
            "curriculo_3.pdf\n",
            "curriculo_4.pdf\n",
            "curriculo_5.pdf\n",
            "curriculo_6.pdf\n",
            "curriculo_7.pdf\n",
            "curriculo_8.pdf\n",
            "curriculo_9.pdf\n",
            "Currículo - Gabriel Arthur.pdf\n",
            "Currículo - Gabriel Carvalho.pdf\n",
            "Currículo - Hiago Aires.pdf\n",
            "Currículo - Joâo Victor.pdf\n",
            "Currículo - Lucas Larry.pdf\n",
            "Currículo - Pedro Mélo.pdf\n",
            "Todos os arquivos foram processados e salvos em 'curriculosMD'.\n",
            "Total processados: 67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preencha os detalhes de requisitos da vaga aqui."
      ],
      "metadata": {
        "id": "SvHuRVZ-oj1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Divida os valores estritamente por vírgula.\n",
        "# Insira somente os valores para cargo, habilidades e idiomas\n",
        "input_rh = {\n",
        "    'habilidades': 'Java,Spring,Docker,Scrum',\n",
        "    'idiomas': 'Português,Inglês',\n",
        "    'cargo': 'Desenvolvedor de Software Sênior'\n",
        "}"
      ],
      "metadata": {
        "id": "SSYlJ9Y5opn3"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sumarização (RAG)"
      ],
      "metadata": {
        "id": "CbRrvA5gcEy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inicialização do motor de busca"
      ],
      "metadata": {
        "id": "rdMH0z_unmaS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "import google.generativeai as genai\n",
        "from langchain_community.chat_models import ChatOllama\n",
        "\n",
        "\n",
        "from langchain.chat_models import init_chat_model\n",
        "\n",
        "SYSTEM_INSTRUCTION = (\n",
        "  \"Atuar como extrator de informações de currículos em PT-BR.\"\n",
        "  \"Usar SOMENTE o conteúdo do contexto recuperado.\"\n",
        "  \"Ser objetivo e citar apenas fatos presentes no contexto.\"\n",
        "  \"Em caso de ausência, retornar [] (array vazio).\"\n",
        "  \"NÃO inferir por padrão (ex.: não assumir 'inglês' por ter trabalhado com empresa dos EUA).\"\n",
        "  \"NÃO confundir 'linguagens de programação' com 'idiomas falados'.\"\n",
        "  \"NÃO inventar nomes, empresas, datas ou níveis.\"\n",
        "  \"Responder EXCLUSIVAMENTE em JSON válido, sem texto extra.\"\n",
        ")\n",
        "\n",
        "# Instancia o modelo\n",
        "llm = ChatOllama(\n",
        "    model=\"llama3.1:8b\",\n",
        "    base_url=\"http://localhost:11434\",\n",
        "    system_instruction=SYSTEM_INSTRUCTION\n",
        ")"
      ],
      "metadata": {
        "id": "jpRKVAz6puX7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c94ab64b-6620-4871-a9ce-73b4451910c4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-3337361684.py:23: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
            "  llm = ChatOllama(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Criação do banco vetorial"
      ],
      "metadata": {
        "id": "ZUC6xwrynsKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.vectorstores import InMemoryVectorStore\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "import json, re\n",
        "from typing import List, Dict, Tuple\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n",
        "\n",
        "def criar_banco_vetorial(\n",
        "    curriculos_markdown: List[str],\n",
        "    embedding_model: HuggingFaceEmbeddings,\n",
        "    chunk_size: int = 200,\n",
        "    chunk_overlap: int = 50,\n",
        ") -> Tuple[InMemoryVectorStore, Dict[str, List[str]]]:\n",
        "    \"\"\"\n",
        "    Recebe lista de currículos em markdown.\n",
        "    Retorna: (vectorstore, chunks_map) onde chunks_map[source_id] = [chunks...]\n",
        "    \"\"\"\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=chunk_size,\n",
        "        chunk_overlap=chunk_overlap\n",
        "    )\n",
        "\n",
        "    print(f\"curriculos_markdown '{curriculos_markdown}\")\n",
        "\n",
        "    texts = []\n",
        "    metadatas = []\n",
        "    chunks_map = {}\n",
        "\n",
        "    for idx, texto in enumerate(curriculos_markdown):\n",
        "        source_id = f\"curr_{idx}\"\n",
        "        chunks = splitter.split_text(curriculos_markdown[texto])\n",
        "        chunks_map[source_id] = chunks\n",
        "        # print(f\"CHUNKS: '{chunks}\")\n",
        "        for c in chunks:\n",
        "            texts.append(c)\n",
        "            metadatas.append({\"source\": source_id})\n",
        "\n",
        "\n",
        "    vectorstore = InMemoryVectorStore.from_texts(\n",
        "        texts=texts,\n",
        "        embedding=embedding_model,\n",
        "        metadatas=metadatas\n",
        "    )\n",
        "\n",
        "    return vectorstore, chunks_map\n"
      ],
      "metadata": {
        "id": "MzWYFPlKcF98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa15e4bd-1668-416d-bf8a-30aa37b068aa"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1282403355.py:7: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Busca dos valores no currículo"
      ],
      "metadata": {
        "id": "4GIGWPmhnugk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_to_list(text: str) -> List[str]:\n",
        "    text = text.strip()\n",
        "    # tenta JSON primeiro\n",
        "    try:\n",
        "        obj = json.loads(text)\n",
        "        if isinstance(obj, list):\n",
        "            return [str(x).strip() for x in obj]\n",
        "        # se for dict, pega valores planos\n",
        "        if isinstance(obj, dict):\n",
        "            # junta todas strings internas num array\n",
        "            vals = []\n",
        "            for v in obj.values():\n",
        "                if isinstance(v, list):\n",
        "                    vals.extend([str(x).strip() for x in v])\n",
        "                else:\n",
        "                    vals.append(str(v).strip())\n",
        "            return vals\n",
        "    except Exception:\n",
        "        pass\n",
        "\n",
        "    # heurística: linhas em forma de bullet\n",
        "    lines = [l.strip() for l in text.splitlines() if l.strip()]\n",
        "    bullets = []\n",
        "    for l in lines:\n",
        "        m = re.match(r\"^[-–•\\*]\\s*(.+)\", l)\n",
        "        if m:\n",
        "            bullets.append(m.group(1).strip())\n",
        "    if bullets:\n",
        "        return bullets\n",
        "\n",
        "    # heurística: vírgula-separado\n",
        "    if \",\" in text:\n",
        "        parts = [p.strip() for p in re.split(r\",|\\|\", text) if p.strip()]\n",
        "        if parts:\n",
        "            return parts\n",
        "\n",
        "    # fallback: todo o texto como 1 item (se curto), ou vazio\n",
        "    if len(text) > 0 and len(text.split()) <= 6:\n",
        "        return [text]\n",
        "    return []\n",
        "\n",
        "def analisar_curriculo(\n",
        "    vectorstore: InMemoryVectorStore,\n",
        "    chunks_map: Dict[str, List[str]],\n",
        "    curriculo_id: str,\n",
        "    k: int = 8,\n",
        "    top_k_retrieval: int = 100,\n",
        ") -> Dict[str, List[str]]:\n",
        "    \"\"\"\n",
        "    Retorna {'habilidades': [...], 'idiomas': [...] } para o curriculo_id.\n",
        "    curriculo_id deve existir em chunks_map (ex: \"curr_0\").\n",
        "    \"\"\"\n",
        "    if curriculo_id not in chunks_map:\n",
        "        raise ValueError(\"curriculo_id não encontrado em chunks_map\")\n",
        "\n",
        "    perguntas = {\n",
        "      \"habilidades\": (\n",
        "        \"Extrair apenas habilidades técnicas (tecnologias, ferramentas, linguagens de programação, frameworks) \"\n",
        "        \"mencionadas literalmente no contexto. \"\n",
        "        \"Ignorar soft skills genéricas (ex.: 'comunicação', 'trabalho em equipe') a menos que estejam em uma seção de 'Habilidades' \"\n",
        "        \"ou listadas como requisito técnico. \"\n",
        "        \"Retornar um array JSON de strings normalizadas (ex.: 'Python', 'SQL', 'TensorFlow'). \"\n",
        "        \"Deduplicar mantendo capitalização canônica (ex.: 'Node.js', 'React', 'PostgreSQL'). \"\n",
        "        \"Se não houver, responder [].\"\n",
        "      ),\n",
        "\n",
        "      \"idiomas\": (\n",
        "        \"Extrair apenas IDIOMAS FALADOS/ESCRITOS humanos (ex.: 'Português', 'Inglês', 'Espanhol', 'Francês', 'Alemão', 'Italiano', \"\n",
        "        \"'Mandarim', 'Japonês'). \"\n",
        "        \"Usar a seguinte WHITELIST e mapeamentos: \"\n",
        "        \"  - Portugues|Português|Pt-BR -> 'Português' \"\n",
        "        \"  - Ingles|Inglês|English -> 'Inglês' \"\n",
        "        \"  - Espanhol|Castelhano|Spanish -> 'Espanhol' \"\n",
        "        \"  - Frances|Francês|French -> 'Francês' \"\n",
        "        \"  - Alemao|Alemão|German -> 'Alemão' \"\n",
        "        \"  - Italiano|Italian -> 'Italiano' \"\n",
        "        \"  - Mandarim|Chinês (quando se referir a idioma) -> 'Mandarim' \"\n",
        "        \"  - Japones|Japonês -> 'Japonês' \"\n",
        "        \"Permitir também: 'Russo', 'Árabe', 'Hindi', 'Coreano'. \"\n",
        "        \"Ignorar TUDO que não for idioma humano (ex.: 'Java', 'Python', 'SQL', 'HTML', 'CSS', 'React', 'Node.js'). \"\n",
        "        \"Ignorar países/cidades/cidadania (ex.: 'Brasileiro', 'São Paulo'). \"\n",
        "        \"Aceitar níveis quando aparecerem, mas NÃO os incluir na resposta (ex.: 'Inglês avançado' -> 'Inglês'). \"\n",
        "        \"Retornar um array JSON de idiomas padronizados conforme mapeamento. \"\n",
        "        \"Se não houver, responder [].\"\n",
        "      ),\n",
        "\n",
        "      \"cargo\": (\n",
        "            \"Extrair apenas o cargo atual ou mais recente ocupado pelo candidato (ex.: 'Desenvolvedor Back-end', 'Analista de Dados', \"\n",
        "            \"'Engenheiro de Software', 'Estagiário de TI'). \"\n",
        "            \"Ignorar cargos de vagas desejadas, objetivos profissionais ou experiências muito antigas quando não estiver claro. \"\n",
        "            \"Priorizar expressões como 'Cargo atual', 'Posição atual', 'Desde', 'Atualmente', 'Empregado como'. \"\n",
        "            \"Retornar um array JSON de strings (mesmo que contenha apenas um cargo). \"\n",
        "            \"Se não houver informação, responder [].\"\n",
        "      )\n",
        "    }\n",
        "\n",
        "    saida = {}\n",
        "    for chave, pergunta in perguntas.items():\n",
        "        retrieved = vectorstore.similarity_search(pergunta, k=top_k_retrieval)\n",
        "        relevant = [d for d in retrieved if d.metadata.get(\"source\") == curriculo_id]\n",
        "\n",
        "        if len(relevant) >= k:\n",
        "            contexto_chunks = [d.page_content for d in relevant[:k]]\n",
        "        else:\n",
        "            contexto_chunks = chunks_map[curriculo_id][:k]\n",
        "\n",
        "        contexto = \"\\n\\n\".join(contexto_chunks)\n",
        "\n",
        "        system_msg = (\n",
        "            \"Você é um assistente de RH que extrai informações de currículos. \"\n",
        "            \"Responda APENAS com um JSON array válido (ex: [\\\"Java\\\", \\\"Spring\\\"]) \"\n",
        "            \"correspondente à pergunta. Se não houver itens, retorne [].\"\n",
        "        )\n",
        "        user_msg = (\n",
        "            f\"Contexto (trechos do currículo):\\n{contexto}\\n\\n\"\n",
        "            f\"Pergunta: {pergunta}\\n\\n\"\n",
        "        )\n",
        "\n",
        "        response = llm.invoke([\n",
        "            {\"role\": \"system\", \"content\": system_msg},\n",
        "            {\"role\": \"user\", \"content\": user_msg}\n",
        "        ])\n",
        "\n",
        "        text = response.content.strip()\n",
        "        parsed = parse_to_list(text)\n",
        "        saida[chave] = parsed\n",
        "\n",
        "    return saida"
      ],
      "metadata": {
        "id": "4q8kwAXMpg2G"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Execução do RAG"
      ],
      "metadata": {
        "id": "VFJLbUG1nzn3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore, chunks_map = criar_banco_vetorial(curriculos, embedding_model)\n",
        "\n",
        "\n",
        "curriculos_analisados = {}\n",
        "\n",
        "print(\"Iniciando a análise dos currículos...\")\n",
        "for i in range(len(curriculos)):\n",
        "    cid = f\"curr_{i}\"\n",
        "    print(f\"\\nAnalisando currículo: {cid}\")\n",
        "\n",
        "    try:\n",
        "        resultado = analisar_curriculo(\n",
        "            vectorstore,\n",
        "            chunks_map,\n",
        "            curriculo_id=cid\n",
        "        )\n",
        "        curriculos_analisados[cid] = resultado\n",
        "        print(f\"Resultado para {cid}: {resultado}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Erro ao analisar {cid}: {e}\")\n",
        "\n",
        "print(\"\\nAnálise concluída.\")\n",
        "print(curriculos_analisados)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RvJmgAUkupkT",
        "outputId": "f426b7b7-8f13-4b56-9a7c-f8168149e6de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "curriculos_markdown '{'Débora Rocha': '## Débora Rocha\\n\\nData de Nascimento: 02/01/1987 Endereço: Brasília, AM Contato: - E-mail: débora@exemplo.com - Telefone: (83) 94266-1333\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2015-2017 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2014\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Ulisses Dias': '## Ulisses Dias\\n\\nData de Nascimento: 23/12/1983 Endereço: Brasília, MG Contato:\\n\\n- E-mail: ulisses@exemplo.com - Telefone: (83) 91831-4590\\n\\n## Objetivo\\n\\nAtuar como Engenheiro de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, SQL, Spark e Hadoop. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheiro de Dados Período: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando Python, SQL. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheiro de Dados Junior Período: 2012-2014\\n\\nAtividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão:\\n\\n2014\\n\\n## Habilidades\\n\\nPython, SQL, Spark, Hadoop\\n\\n## Idiomas\\n\\nPortuguês', 'Talita Oliveira': '## Talita Oliveira\\n\\nData de Nascimento: 03/09/2000 Endereço: Manaus, SP Contato: - E-mail: talita@exemplo.com - Telefone: (83) 96590-1207\\n\\n## Objetivo\\n\\nAtuar como DevOps Engineer em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em AWS, Docker, Kubernetes e Terraform. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - DevOps Engineer Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando AWS, Docker. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - DevOps Engineer Junior Período: 2013-2015 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão: 2013\\n\\n## Habilidades\\n\\nAWS, Docker, Kubernetes, Terraform\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Alemão', 'Íris Pinto': '## Íris Pinto\\n\\nData de Nascimento: 14/03/1996 Endereço: Natal, CE Contato: - E-mail: íris@exemplo.com - Telefone: (83) 95425-9817\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2013-2015 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2016\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol, Francês', 'Ulisses Melo': '## Ulisses Melo\\n\\nData de Nascimento: 09/08/1987 Endereço: Belém, PE Contato: - E-mail: ulisses@exemplo.com - Telefone: (83) 98613-7209\\n\\n## Objetivo\\n\\nAtuar como DevOps Engineer em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em AWS, Docker, Kubernetes e Terraform. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - DevOps Engineer Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando AWS, Docker. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - DevOps Engineer Junior Período: 2013-2015 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nAWS, Docker, Kubernetes, Terraform\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Íris Vaz': '## Íris Vaz\\n\\nData de Nascimento: 17/04/1999 Endereço: Natal, PR Contato: - E-mail: íris@exemplo.com - Telefone: (83) 95115-7844\\n\\n## Objetivo\\n\\nAtuar como Analista de QA em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Testes Automatizados, Selenium, Cypress e Jenkins. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de QA Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Testes Automatizados, Selenium. Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de QA Junior Período: 2013-2015 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação\\n\\nConclusão: 2013\\n\\n## Habilidades\\n\\nTestes Automatizados, Selenium, Cypress, Jenkins\\n\\n- Universidade Federal\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'Júlia Moura': '## Júlia Moura\\n\\nData de Nascimento: 27/12/1982 Endereço: Natal, PB Contato: - E-mail: júlia@exemplo.com - Telefone: (83) 94143-9598\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Back-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Java, Spring Boot, SQL e Docker. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Back-end Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Java, Spring Boot. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Back-end Junior Período: 2013-2015 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão:\\n\\n2016\\n\\n## Habilidades\\n\\nJava, Spring Boot, SQL, Docker\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Mônica Gomes': '## Mônica Gomes\\n\\nData de Nascimento: 09/06/1985 Endereço: Curitiba, RN Contato: - E-mail: mônica@exemplo.com - Telefone: (83) 92876-3683\\n\\n## Objetivo\\n\\nAtuar como Gerente de Projetos em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Scrum, Kanban, JIRA e Gestão de Equipes. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Gerente de Projetos Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Scrum, Kanban. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Gerente de Projetos Junior Período: 2012-2014 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nScrum, Kanban, JIRA, Gestão de Equipes\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Mônica Azevedo': '## Mônica Azevedo\\n\\nData de Nascimento: 21/10/1986 Endereço: Curitiba, RJ Contato: - E-mail: mônica@exemplo.com - Telefone: (83) 97291-9099\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Full Stack em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Node.js, React, MongoDB e GraphQL. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Full Stack Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Node.js, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Full Stack Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nNode.js, React, MongoDB, GraphQL\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Vitor Gomes': '## Vitor Gomes\\n\\nData de Nascimento: 16/08/1985 Endereço: Belém, CE Contato: - E-mail: vitor@exemplo.com - Telefone: (83) 94108-7277\\n\\n## Objetivo\\n\\nAtuar como Analista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em SQL, Power BI, Excel e Python. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Dados Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando SQL, Power BI. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Dados Junior Período: 2012-2014 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2014\\n\\n## Habilidades\\n\\nSQL, Power BI, Excel, Python\\n\\n## Idiomas\\n\\nPortuguês, Espanhol', 'Mônica Rocha': '## Mônica Rocha\\n\\nData de Nascimento: 27/04/1987 Endereço: São Paulo, MG Contato: - E-mail: mônica@exemplo.com - Telefone: (83) 91387-4164\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2016-2018 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol, Francês', 'João Costa': '## João Costa\\n\\nData de Nascimento: 18/05/1998 Endereço: Natal, SC\\n\\n## Contato:\\n\\n- E-mail: joão@exemplo.com - Telefone: (83) 98019-7543\\n\\n## Objetivo\\n\\nAtuar como Engenheiro de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, SQL, Spark e Hadoop. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheiro de Dados Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Python, SQL. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheiro de Dados Junior Período: 2015-2017 Atividades:\\n\\n- Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2017\\n\\n## Habilidades\\n\\nPython, SQL, Spark, Hadoop\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Amanda Silva': '## Amanda Silva\\n\\nData de Nascimento: 06/07/1992 Endereço: Florianópolis, RJ Contato: - E-mail: amanda@exemplo.com - Telefone: (83) 98317-4201\\n\\n## Objetivo\\n\\nAtuar como Analista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em SQL, Power BI, Excel e Python. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Dados Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando SQL, Power BI. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Dados Junior Período: 2012-2014 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2017\\n\\n## Habilidades\\n\\nSQL, Power BI, Excel, Python\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'Talita Araújo': '## Talita Araújo\\n\\nData de Nascimento: 04/08/1986 Endereço: Campina Grande, RN Contato: - E-mail: talita@exemplo.com - Telefone: (83) 99606-2951\\n\\n## Objetivo\\n\\nAtuar como DevOps Engineer em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em AWS, Docker, Kubernetes e Terraform. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - DevOps Engineer Período: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando AWS, Docker. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - DevOps Engineer Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nAWS, Docker, Kubernetes, Terraform\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol, Francês', 'Vitor Machado': '## Vitor Machado\\n\\nData de Nascimento: 15/11/1986 Endereço: Curitiba, PR Contato: - E-mail: vitor@exemplo.com - Telefone: (83) 99375-8752\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Mobile em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Kotlin, Swift, React Native e Firebase. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Mobile Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Kotlin, Swift. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Mobile Junior Período: 2014-2016\\n\\nAtividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2015\\n\\n## Habilidades\\n\\nKotlin, Swift, React Native, Firebase\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'Yasmin Freitas': '## Yasmin Freitas\\n\\nData de Nascimento: 23/12/1993 Endereço: Belém, PA Contato: - E-mail: yasmin@exemplo.com - Telefone: (83) 99414-9085\\n\\n## Objetivo\\n\\nAtuar como Engenheiro de Software em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em C#, .NET, Azure e SQL Server. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheiro de Software Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando C#, .NET. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheiro de Software Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nC#, .NET, Azure, SQL Server\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Wilson Ramos': '## Wilson Ramos\\n\\nData de Nascimento: 17/05/1984 Endereço: Florianópolis, BA Contato: - E-mail: wilson@exemplo.com - Telefone: (83) 96718-2127\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Front-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em JavaScript, React, Vue.js e CSS. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Front-end Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando JavaScript, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Front-end Junior Período: 2016-2018 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2014\\n\\n## Habilidades\\n\\nJavaScript, React, Vue.js, CSS\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Patrícia Barros': '## Patrícia Barros\\n\\nData de Nascimento: 13/05/1994 Endereço: Belém, PE Contato:\\n\\n- E-mail: patrícia@exemplo.com - Telefone: (83) 96977-3664\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Front-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em JavaScript, React, Vue.js e CSS. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Front-end Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando JavaScript, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Front-end Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nJavaScript, React, Vue.js, CSS\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Otávio Azevedo': '## Otávio Azevedo\\n\\nData de Nascimento: 08/11/1989 Endereço: Belém, DF\\n\\n## Contato:\\n\\n- E-mail: otávio@exemplo.com - Telefone: (83) 94680-4262\\n\\n## Objetivo\\n\\nAtuar como DevOps Engineer em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em AWS, Docker, Kubernetes e Terraform. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - DevOps Engineer Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando AWS, Docker. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - DevOps Engineer Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2014\\n\\n## Habilidades\\n\\nAWS, Docker, Kubernetes, Terraform\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Eduardo Sousa': '## Eduardo Sousa\\n\\nData de Nascimento: 08/03/1994 Endereço: Florianópolis, RN Contato: - E-mail: eduardo@exemplo.com - Telefone: (83) 97216-5422\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner\\n\\nPeríodo: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Espanhol', 'Otávio Silva': '## Otávio Silva\\n\\nData de Nascimento: 22/02/1980 Endereço: Belo Horizonte, RN Contato: - E-mail: otávio@exemplo.com - Telefone: (83) 98338-6236\\n\\n## Objetivo\\n\\nAtuar como Engenheiro de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 2 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, SQL, Spark e Hadoop. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheiro de Dados Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando Python, SQL. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheiro de Dados Junior Período: 2016-2018 Atividades:\\n\\n- Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nPython, SQL, Spark, Hadoop\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Débora Dias': '## Débora Dias\\n\\nData de Nascimento: 25/03/1982 Endereço: Campina Grande, RN Contato: - E-mail: débora@exemplo.com - Telefone: (83) 91374-6774\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner Período: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2015-2017 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2014\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol, Francês', 'Carlos Souza': '## Carlos Souza\\n\\nData de Nascimento: 01/11/1982 Endereço: Salvador, RJ Contato: - E-mail: carlos@exemplo.com - Telefone: (83) 94599-5882\\n\\n## Objetivo\\n\\nAtuar como Analista de Suporte em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Redes, Linux, Scripting Bash e ITIL. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Suporte Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Redes, Linux. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Suporte Junior Período: 2014-2016 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão:\\n\\n2017\\n\\n## Habilidades\\n\\nRedes, Linux, Scripting Bash, ITIL\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Francês', 'Bruno Carvalho': '## Bruno Carvalho\\n\\nData de Nascimento: 26/11/1987 Endereço: Brasília, RJ Contato: - E-mail: bruno@exemplo.com - Telefone: (83) 95371-3608\\n\\n## Objetivo\\n\\nAtuar como Analista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em SQL, Power BI, Excel e Python. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Dados Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando SQL, Power BI. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Dados Junior Período: 2013-2015 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nSQL, Power BI, Excel, Python\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'Beatriz Costa': '## Beatriz Costa\\n\\nData de Nascimento: 13/03/2000 Endereço: Salvador, MG Contato: - E-mail: beatriz@exemplo.com - Telefone: (83) 95915-8491\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'Valentina Melo': '## Valentina Melo\\n\\nData de Nascimento: 04/04/1987 Endereço: Belém, RN Contato: - E-mail: valentina@exemplo.com - Telefone: (83) 91775-7398\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Mobile em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Kotlin, Swift, React Native e Firebase. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Mobile Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Kotlin, Swift. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Mobile Junior Período: 2016-2018\\n\\nAtividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2015\\n\\n## Habilidades\\n\\nKotlin, Swift, React Native, Firebase\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Francês', 'Júlia Brito': '## Júlia Brito\\n\\nData de Nascimento: 04/05/1992 Endereço: Manaus, PA Contato: - E-mail: júlia@exemplo.com - Telefone: (83) 96749-2653\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Carlos Teixeira': '## Carlos Teixeira\\n\\nData de Nascimento: 16/04/1997 Endereço: Belo Horizonte, AM Contato: - E-mail: carlos@exemplo.com - Telefone: (83) 93167-8744\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Front-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em JavaScript, React, Vue.js e CSS. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Front-end Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando JavaScript, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Front-end Junior Período: 2013-2015 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2014\\n\\n## Habilidades\\n\\nJavaScript, React, Vue.js, CSS\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Eduardo Barbosa': '## Eduardo Barbosa\\n\\nData de Nascimento: 19/10/1981 Endereço: Porto Alegre, BA Contato: - E-mail: eduardo@exemplo.com - Telefone: (83) 92343-7868\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Mobile em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Kotlin, Swift, React Native e Firebase. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Mobile Período: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando Kotlin, Swift. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Mobile Junior Período: 2012-2014\\n\\nAtividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão:\\n\\n2017\\n\\n## Habilidades\\n\\nKotlin, Swift, React Native, Firebase\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Íris Melo': '## Íris Melo\\n\\nData de Nascimento: 05/11/1988 Endereço: São Paulo, DF Contato: - E-mail: íris@exemplo.com - Telefone: (83) 93647-8239\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Back-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Java, Spring Boot, SQL e Docker. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\n## Empresa ABC\\n\\n- Desenvolvedor Back-end\\n\\nPeríodo: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Java, Spring Boot. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Back-end Junior Período: 2012-2014 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2013\\n\\n## Habilidades\\n\\nJava, Spring Boot, SQL, Docker\\n\\n## Idiomas\\n\\nPortuguês', 'Carlos Gomes': '## Carlos Gomes\\n\\nData de Nascimento: 28/12/1987 Endereço: Manaus, SC Contato: - E-mail: carlos@exemplo.com - Telefone: (83) 93937-7756\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 2 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner\\n\\nPeríodo: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Daniela Rocha': '## Daniela Rocha\\n\\nData de Nascimento: 03/04/1998 Endereço: Rio de Janeiro, MG Contato: - E-mail: daniela@exemplo.com - Telefone: (83) 96155-4483\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Back-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Java, Spring Boot, SQL e Docker. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Back-end Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Java, Spring Boot. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Back-end Junior Período: 2013-2015 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2016\\n\\n## Habilidades\\n\\nJava, Spring Boot, SQL, Docker\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'Carlos Machado': '## Carlos Machado\\n\\nData de Nascimento: 28/05/1980 Endereço: Fortaleza, RS Contato:\\n\\n- E-mail: carlos@exemplo.com - Telefone: (83) 98208-3739\\n\\n## Objetivo\\n\\nAtuar como Analista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em SQL, Power BI, Excel e Python. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Dados Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando SQL, Power BI. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Dados Junior Período: 2013-2015 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nSQL, Power BI, Excel, Python\\n\\n## Idiomas\\n\\nPortuguês', 'Amanda Brito': '## Amanda Brito\\n\\nData de Nascimento: 08/08/1998 Endereço: Rio de Janeiro, MG Contato: - E-mail: amanda@exemplo.com - Telefone: (83) 99496-9498\\n\\n## Objetivo\\n\\nAtuar como Engenheiro de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, SQL, Spark e Hadoop. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheiro de Dados Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Python, SQL. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheiro de Dados Junior Período: 2014-2016 Atividades:\\n\\n- Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nPython, SQL, Spark, Hadoop\\n\\n## Idiomas\\n\\nPortuguês', 'Patrícia Lima': '## Patrícia Lima\\n\\nData de Nascimento: 08/10/1987 Endereço: Porto Alegre, SC Contato: - E-mail: patrícia@exemplo.com - Telefone: (83) 91117-2163\\n\\n## Objetivo\\n\\nAtuar como DevOps Engineer em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em AWS, Docker, Kubernetes e Terraform. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - DevOps Engineer Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando AWS, Docker. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - DevOps Engineer Junior Período: 2015-2017 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nAWS, Docker, Kubernetes, Terraform\\n\\n## Idiomas\\n\\nPortuguês', 'Carlos Araújo': '## Carlos Araújo\\n\\nData de Nascimento: 12/09/1993 Endereço: Manaus, PE Contato: - E-mail: carlos@exemplo.com - Telefone: (83) 93532-4878\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Otávio Moura': '## Otávio Moura\\n\\nData de Nascimento: 02/01/1980 Endereço: Natal, RJ Contato: - E-mail: otávio@exemplo.com - Telefone: (83) 95923-1812\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Front-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em JavaScript, React, Vue.js e CSS. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Front-end Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando JavaScript, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Front-end Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão:\\n\\n2016\\n\\n## Habilidades\\n\\nJavaScript, React, Vue.js, CSS\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Francês', 'Júlia Monteiro': '## Júlia Monteiro\\n\\nData de Nascimento: 21/09/1980 Endereço: Porto Alegre, DF Contato: - E-mail: júlia@exemplo.com - Telefone: (83) 95905-2697\\n\\n## Objetivo\\n\\nAtuar como Analista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em SQL, Power BI, Excel e Python. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Dados Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando SQL, Power BI. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Dados Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nSQL, Power BI, Excel, Python\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Francês', 'Valentina Freitas': '## Valentina Freitas\\n\\nData de Nascimento: 13/11/2000 Endereço: Natal, MG Contato: - E-mail: valentina@exemplo.com - Telefone: (83) 97118-8177\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2014\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Thiago Araújo': '## Thiago Araújo\\n\\nData de Nascimento: 18/06/1980 Endereço: Manaus, PA Contato: - E-mail: thiago@exemplo.com - Telefone: (83) 92889-5279\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner\\n\\nPeríodo: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2016-2018 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão: 2013\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Alemão', 'Fabiana Almeida': '## Fabiana Almeida\\n\\nData de Nascimento: 21/08/1997 Endereço: Porto Alegre, AM Contato: - E-mail: fabiana@exemplo.com - Telefone: (83) 91636-8294\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Mobile em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 3 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Kotlin, Swift, React Native e Firebase. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Mobile Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Kotlin, Swift. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Mobile Junior Período: 2013-2015\\n\\nAtividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2013\\n\\n## Habilidades\\n\\nKotlin, Swift, React Native, Firebase\\n\\n## Idiomas\\n\\nPortuguês, Espanhol', 'João Brito': '## João Brito\\n\\nData de Nascimento: 24/06/1993 Endereço: Natal, RJ Contato: - E-mail: joão@exemplo.com - Telefone: (83) 99304-2801\\n\\n## Objetivo\\n\\nAtuar como Analista de QA em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Testes Automatizados, Selenium, Cypress e Jenkins. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de QA Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Testes Automatizados, Selenium. Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de QA Junior Período: 2014-2016 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão: 2016\\n\\n## Habilidades\\n\\nTestes Automatizados, Selenium, Cypress, Jenkins\\n\\n## Idiomas\\n\\nPortuguês, Espanhol', 'Natália Ferreira': '## Natália Ferreira\\n\\nData de Nascimento: 05/11/1985 Endereço: Belém, PE Contato: - E-mail: natália@exemplo.com - Telefone: (83) 97916-2040\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Full Stack em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Node.js, React, MongoDB e GraphQL. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Full Stack Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Node.js, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Full Stack Junior Período: 2012-2014 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nNode.js, React, MongoDB, GraphQL\\n\\n## Idiomas\\n\\nPortuguês', 'Carlos Freitas': '## Carlos Freitas\\n\\nData de Nascimento: 03/11/1990 Endereço: São Paulo, RJ Contato:\\n\\n- E-mail: carlos@exemplo.com - Telefone: (83) 96143-3041\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Back-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Java, Spring Boot, SQL e Docker. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Back-end Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando Java, Spring Boot. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Back-end Junior Período: 2012-2014 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2015\\n\\n## Habilidades\\n\\nJava, Spring Boot, SQL, Docker\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Ulisses Barros': '## Ulisses Barros\\n\\nData de Nascimento: 23/06/1988 Endereço: Recife, BA Contato:\\n\\n- E-mail: ulisses@exemplo.com - Telefone: (83) 96915-2084\\n\\n## Objetivo\\n\\nAtuar como Engenheiro de Software em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 8 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em C#, .NET, Azure e SQL Server. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheiro de Software Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando C#, .NET. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheiro de Software Junior Período: 2012-2014 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão:\\n\\n2015\\n\\n## Habilidades\\n\\nC#, .NET, Azure, SQL Server\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'Talita Nascimento': '## Talita Nascimento\\n\\nData de Nascimento: 22/04/1994 Endereço: Belém, PB Contato: - E-mail: talita@exemplo.com - Telefone: (83) 97351-3074\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2016-2021 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2017\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\nPortuguês, Espanhol', 'Yasmin Ramos': '## Yasmin Ramos\\n\\nData de Nascimento: 07/02/1998 Endereço: Rio de Janeiro, RN Contato: - E-mail: yasmin@exemplo.com - Telefone: (83) 94978-2669\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2012-2014 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2013\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Alemão', 'curriculo_1': '## Ana Paula Silva\\n\\nData de Nascimento: 12/04/1990 Endereço: Campina Grande, PB\\n\\n## Contato:\\n\\n- E-mail: ana@exemplo.com - Telefone: (83) 97608-9592\\n\\n## Objetivo\\n\\nAtuar como Engenheira de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, SQL, Spark e Hadoop. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheira de Dados Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Python, SQL. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheira de Dados Junior Período: 2014-2016 Atividades:\\n\\n- Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nPython, SQL, Spark, Hadoop\\n\\n## Idiomas\\n\\nInglês, Português', 'curriculo_10': '## Juliana Monteiro Pires\\n\\nData de Nascimento: 09/05/1986 Endereço: Porto Alegre, RS\\n\\nContato:\\n\\n- E-mail: juliana@exemplo.com - Telefone: (83) 95570-6997\\n\\n## Objetivo\\n\\nAtuar como Analista de QA em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Testes Automatizados, Selenium, Cypress e Jenkins. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de QA Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Testes Automatizados, Selenium. Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de QA Junior Período: 2015-2017 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão: 2017\\n\\n## Habilidades\\n\\nTestes Automatizados, Selenium, Cypress, Jenkins\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'curriculo_11': '## Lucas Moreira Andrade\\n\\nData de Nascimento: 21/03/1994 Endereço: Manaus, AM Contato: - E-mail: lucas@exemplo.com - Telefone: (83) 97796-9525\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Full Stack em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Node.js, React, MongoDB e GraphQL. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Full Stack Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Node.js, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Full Stack Junior Período: 2017-2019 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nNode.js, React, MongoDB, GraphQL\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Italiano', 'curriculo_12': '## Mariana Duarte Ferreira\\n\\nData de Nascimento: 14/10/1988 Endereço: Natal, RN Contato: - E-mail: mariana@exemplo.com - Telefone: (83) 93639-5353\\n\\n## Objetivo\\n\\nAtuar como Product Owner em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Roadmapping, User Stories, Scrum e Analytics. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Product Owner\\n\\nPeríodo: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Roadmapping, User Stories. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Product Owner Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2017\\n\\n## Habilidades\\n\\nRoadmapping, User Stories, Scrum, Analytics\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Francês', 'curriculo_13': '## Nicolas Vaz Torres\\n\\nData de Nascimento: 04/01/1992 Endereço: Brasília, DF Contato: - E-mail: nicolas@exemplo.com - Telefone: (83) 94010-5370\\n\\n## Objetivo\\n\\nAtuar como Analista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em SQL, Power BI, Excel e Python. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Dados Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando SQL, Power BI. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Dados Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2014\\n\\n## Habilidades\\n\\nSQL, Power BI, Excel, Python\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'curriculo_14': '## Priscila Soares Martins\\n\\nData de Nascimento: 16/08/1991 Endereço: Belém, PA Contato: - E-mail: priscila@exemplo.com - Telefone: (83) 92604-4849\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedora Android em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 2 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Kotlin, Java, Android SDK e REST APIs. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedora Android Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Kotlin, Java. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedora Android Junior Período: 2015-2017 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2017\\n\\n## Habilidades\\n\\nKotlin, Java, Android SDK, REST APIs\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Espanhol', 'curriculo_2': '## Bruno Henrique Costa\\n\\nData de Nascimento: 23/08/1992 Endereço: Recife, PE Contato:\\n\\n- E-mail: bruno@exemplo.com - Telefone: (83) 99394-7543\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Front-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 2 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em JavaScript, React, TypeScript e CSS. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Front-end Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando JavaScript, React. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Front-end Junior Período: 2017-2019 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2017\\n\\n## Habilidades\\n\\nJavaScript, React, TypeScript, CSS\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'curriculo_3': '## Camila Oliveira Santos\\n\\nData de Nascimento: 05/11/1988 Endereço: Fortaleza, CE Contato:\\n\\n- E-mail: camila@exemplo.com - Telefone: (83) 91514-1774\\n\\n## Objetivo\\n\\nAtuar como Cientista de Dados em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 5 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Python, Pandas, Scikit-learn e TensorFlow. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Cientista de Dados Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Python, Pandas. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Cientista de Dados Junior Período: 2017-2019 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nPython, Pandas, Scikit-learn, TensorFlow\\n\\n## Idiomas\\n\\n## Português, Espanhol, Inglês', 'curriculo_4': '## Daniel Almeida Souza\\n\\nData de Nascimento: 17/06/1991 Endereço: Salvador, BA Contato: - E-mail: daniel@exemplo.com - Telefone: (83) 93334-9856\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Back-end em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 2 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Java, Spring Boot, SQL e Docker. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Back-end Período: 2017-2022 Atividades: - Desenvolvimento de soluções utilizando Java, Spring Boot. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Back-end Junior Período: 2017-2019 - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e\\n\\nAtividades: integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2017\\n\\n## Habilidades\\n\\nJava, Spring Boot, SQL, Docker\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'curriculo_5': '## Eduardo Gomes Pereira\\n\\nData de Nascimento: 30/01/1985 Endereço: Belo Horizonte, MG Contato: - E-mail: eduardo@exemplo.com - Telefone: (83) 98216-5895\\n\\n## Objetivo\\n\\nAtuar como Analista de Suporte em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 4 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Redes, Linux, Scripting Bash e ITIL. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Analista de Suporte Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando Redes, Linux. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Analista de Suporte Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2015\\n\\n## Habilidades\\n\\nRedes, Linux, Scripting Bash, ITIL\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'curriculo_6': '## Fernanda Rocha Nunes\\n\\nData de Nascimento: 12/09/1989 Endereço: São Paulo, SP Contato: - E-mail: fernanda@exemplo.com - Telefone: (83) 98295-1288\\n\\n## Objetivo\\n\\nAtuar como Engenheira de Software em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em C#, .NET, Azure e SQL Server. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Engenheira de Software Período: 2018-2023 Atividades: - Desenvolvimento de soluções utilizando C#, .NET. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Engenheira de Software Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão:\\n\\n2015\\n\\n## Habilidades\\n\\nC#, .NET, Azure, SQL Server\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Alemão', 'curriculo_7': '## Guilherme Freitas Lima\\n\\nData de Nascimento: 19/02/1993 Endereço: Rio de Janeiro, RJ Contato: - E-mail: guilherme@exemplo.com - Telefone: (83) 95815-1997\\n\\n## Objetivo\\n\\nAtuar como Desenvolvedor Mobile em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Kotlin, Swift, React Native e Firebase. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Desenvolvedor Mobile Período: 2020-2024 Atividades: - Desenvolvimento de soluções utilizando Kotlin, Swift. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Desenvolvedor Mobile Junior Período: 2017-2019 Atividades:\\n\\n- Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal\\n\\nConclusão: 2014\\n\\n## Habilidades\\n\\nKotlin, Swift, React Native, Firebase\\n\\n## Idiomas\\n\\nPortuguês, Inglês, Francês', 'curriculo_8': '## Helena Castro Ribeiro\\n\\nData de Nascimento: 27/07/1987 Endereço: Curitiba, PR Contato:\\n\\n- E-mail: helena@exemplo.com - Telefone: (83) 94658-4833\\n\\n## Objetivo\\n\\nAtuar como Gerente de Projetos em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 7 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em Scrum, Kanban, JIRA e Gestão de Equipes. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - Gerente de Projetos Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando Scrum, Kanban. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - Gerente de Projetos Junior Período: 2014-2016 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\n## Bacharelado em Ciência da Computação - Universidade Federal\\n\\n## Conclusão: 2017\\n\\n## Habilidades\\n\\nScrum, Kanban, JIRA, Gestão de Equipes\\n\\n## Idiomas\\n\\n## Português, Espanhol, Inglês', 'curriculo_9': '## Igor Fernandes Teixeira\\n\\nData de Nascimento: 13/12/1990 Endereço: Florianópolis, SC Contato: - E-mail: igor@exemplo.com - Telefone: (83) 92398-6299\\n\\n## Objetivo\\n\\nAtuar como DevOps Engineer em empresas de tecnologia, contribuindo com minhas habilidades técnicas e experiência para o desenvolvimento de soluções inovadoras.\\n\\n## Resumo Profissional\\n\\nProfissional com experiência de mais de 6 anos na área de tecnologia da informação, com atuação em projetos de diferentes segmentos. Possuo forte conhecimento em AWS, Docker, Kubernetes e Terraform. Tenho facilidade em trabalhar em equipe e adaptar-me a novos ambientes.\\n\\n## Experiência Profissional\\n\\nEmpresa ABC - DevOps Engineer Período: 2019-2024 Atividades: - Desenvolvimento de soluções utilizando AWS, Docker. - Colaboração com equipes multidisciplinares e metodologias ágeis (Scrum/Kanban). - Manutenção e melhoria contínua de sistemas existentes. Empresa XYZ - DevOps Engineer Junior Período: 2017-2019 Atividades: - Suporte no desenvolvimento e testes de aplicações. - Documentação de processos e integração de sistemas.\\n\\n## Formação Acadêmica\\n\\nBacharelado em Ciência da Computação - Universidade Federal Conclusão: 2016\\n\\n## Habilidades\\n\\nAWS, Docker, Kubernetes, Terraform\\n\\n## Idiomas\\n\\nPortuguês, Inglês', 'Currículo - Gabriel Arthur': '## GABRIEL ARTHUR GOMES DOS SANTOS\\n\\nCampina Grande, PB | (83) 99680-0191 | garthur.san@icloud.com | linkedin\\n\\n## RESUMO PROFISSIONAL\\n\\nDesenvolvedor Salesforce Sênior com vasta experiência na arquitetura e implementação de soluções complexas tanto em Salesforce Core quanto em Salesforce Industries (Vlocity) . Especialista em Apex , automações robustas com Flows e na construção de integrações via APIs REST/SOAP. Experiência comprovada na refatoração de código legado para otimização de performance e na liderança de funcionalidades end-to-end em projetos de grande escala, como a implementação de Industries CPQ na nuvem Energy &amp; Utilities Cloud .\\n\\n## COMPETÊNCIAS TÉCNICAS\\n\\n- Desenvolvimento Salesforce Core: Apex (Triggers, Batches, Schedulers), Flows (todos os tipos), Lightning Web Components (LWC), SOQL, SOSL.\\n- Salesforce Industries &amp; OmniStudio: OmniScript, DataRaptors, Integration Procedures, FlexCards, Industries CPQ.\\n- Integrações: APIs REST &amp; SOAP, Connected Apps, Named Credentials.\\n- Qualidade e Performance: Refatoração de Código, Otimização de Performance, Testes Unitários.\\n- Nuvens Salesforce: Energy &amp; Utilities Cloud, Sales Cloud, Service Cloud.\\n- Ferramentas: Git, VS Code.\\n\\n## EXPERIÊNCIA PROFISSIONAL\\n\\nCaixa Econômica Federal | Salesforce Developer Agosto de 2025 - Presente\\n\\n- Liderança técnica no desenvolvimento e manutenção de soluções Salesforce Core, com foco em escalabilidade e performance.\\n- Arquitetura e implementação de integrações complexas via APIs REST/SOAP para conectar o Salesforce a sistemas críticos.\\n- Criação de automações robustas para otimizar fluxos de trabalho, utilizando Apex e Flows avançados.\\n- Refatoração de código legado (Apex, Visualforce), aplicando melhores práticas para melhorar a eficiência e a manutenibilidade do sistema.\\n- Manutenção e evolução contínua dos componentes da organização, garantindo a estabilidade e segurança da plataforma.\\n\\n## Accenture | Salesforce Industries Developer Março de 2025 - Agosto de 2025\\n\\n- Liderança na implementação do Industries CPQ, desde o levantamento de requisitos com stakeholders até a definição da arquitetura e do fluxo de cotação de ponta a ponta.\\n- Atuação na implementação e configuração do Industries CPQ (Configure, Price, Quote),\\n- otimizando o processo de cotação e propostas comerciais.\\n- Desenvolvimento e orquestração de jornadas de usuário guiadas com OmniScript, e manipulação de dados com DataRaptors e Integration Procedures, para criar soluções dinâmicas dentro do OmniStudio.\\n- Desenvolvimento de funcionalidades e personalizações específicas na nuvem Salesforce Energy &amp; Utilities Cloud, em um dos maiores projetos do setor no Brasil.\\n- Desenvolvimento de soluções customizadas utilizando LWC e Apex para aprimorar a experiência do usuário.\\n- Concepção e gestão de integrações complexas via REST APIs, incluindo configuração de Connected Apps e Named Credentials.\\n\\n## Kamii | Salesforce Developer\\n\\nFevereiro de 2023 - Março de 2025\\n\\n- Implementação de automação de processos de ponta a ponta usando Flow e Apex, aumentando a eficiência operacional e reduzindo a intervenção manual.\\n- Construção de integrações robustas via API REST com sistemas externos e legados, garantindo a integridade dos dados e a sincronização em tempo real.\\n- Atuação na implementação e configuração do Industries CPQ.\\n- Desenvolvimento de soluções customizadas com Apex e Lightning Web Components (LWC) para atender a requisitos de negócio complexos nas nuvens de Sales e Service Cloud, aprimorando a funcionalidade da plataforma.\\n\\n## CERTIFICAÇÕES E CURSOS\\n\\n- Salesforce AI Associate\\n- Salesforce AI Specialist\\n\\n## FORMAÇÃO ACADÊMICA\\n\\nSistemas de Informação | UNIFACISA 2023 - Em curso\\n\\n## IDIOMAS\\n\\n- ●\\n\\n- Inglês: Nível C1 (Fluente)\\n\\n- ●\\n\\n- Espanhol: Nível A2 (Básico)', 'Currículo - Gabriel Carvalho': '## Gabriel Henrique Lopes Carvalho\\n\\n## Desenvolvedor Front-end\\n\\n<!-- image -->\\n\\n- gabrielhenlc@gmail.com\\n\\n- (83) 99657-1510\\n\\n- Campina Grande - PB LinkedIn\\n\\n- Github\\n\\n- Portfolio\\n\\n## Resumo\\n\\nEstudante de programação há 3 anos, com foco em desenvolvimento web há 2 anos. Proficiente em desenvolvimento Front-end utilizando ReactJS para web e React Native para plataformas mobile, empregando a linguagem TypeScript . Um pensador criativo, altamente crítico e apaixonado pelo trabalho em equipe.\\n\\n<!-- image -->\\n\\n## Habilidades\\n\\n## Front-end\\n\\nJavaScript, TypeScript, HTML, CSS, React, React Native, Next.js, Flutter, Styled-Components, Bootstrap, Tailwind CSS\\n\\n## Banco de Dados\\n\\nMongoDB, PostgreSQL\\n\\n## Idiomas\\n\\nPortuguês - Fluente | Inglês - Avançado | Japonês Iniciante\\n\\n<!-- image -->\\n\\n## Educação\\n\\n## Ciência da Computação, Universidade Federal de Campina Grande\\n\\n2020 - Atual\\n\\nAlgumas das temáticas que estudei envolvem Padrões de projeto, Orientação a objetos, Estrutura de dados e algoritmos, Banco de dados, Matemática discreta, Grafos.\\n\\n## Desenvolvimento Web/Mobile, Ignite Rocketseat\\n\\n- Formação intensiva, baseada no mercado com experiência em projetos práticos\\n- Explorei fundamentos da engenharia de software: Clean Code, Padrão SOLID, Paradigma Funcional, Performance, Testes e Otimização.\\n- Realizei projetos como desafios complementares, visando aprimorar a absorção de conhecimentos;\\n- Participei de comunidades de programação centradas no desenvolvimento web;\\n\\n## Experiência\\n\\n## Desenvolvedor Front end, Projetos Ignite\\n\\n- Desenvolvi mais de 15 aplicações front end de alto nível.\\n- Gerenciei técnicas de otimização de performance, visando melhorar a experiência do cliente.\\n- Apliquei boas práticas de qualidade de código, elaborando testes unitários e de integração.\\n\\n## Monitor, Estrutura de Dados e Algoritmos\\n\\n- Liderei sessões semanais individuais e em grupo destinadas ao esclarecimento de dúvidas;\\n- Análise e supervisão dos alunos para identificar potenciais dificuldades e prover suporte;\\n\\n## Projetos\\n\\n## Ignite Shop\\n\\n04.2022 - 04.2023\\n\\n10.2021 - 05.2022\\n\\n08.2022 - 09.2022\\n\\nUm ecommerce de camisetas. Ignite Shop é uma aplicação web desenvolvida em React, utilizando o framework Next.js, para maior performance no client-side, com a linguagem TypeScript. Possui integração com a API de pagamentos Stripe e estilizado com a biblioteca CSS-in-JS Stitches.\\n\\n## Daily Diet\\n\\n02.2023 - 03.2023\\n\\nUm acompanhamento alimentar. Daily Diet é uma aplicação mobile desenvolvida em React Native, com a linguagem TypeScript. Para armazenamento interno, utiliza o recurso Async Storage. Para estilização, foi empregado a biblioteca de utility-first Native Base.\\n\\n04.2022 - 04.2023\\n\\n## Back-end\\n\\nNode.js, Express, Java\\n\\n## Infraestrutura\\n\\nAPI RESTful, GraphQL, Git', 'Currículo - Hiago Aires': '## OBJETIVO\\n\\n- Buscar oportunidades de projetos e estágios para engrandecer minha profissionalização.\\n\\n## FORMAÇÃO ACADÊMICA\\n\\n- Ciência da Computação - 4o período\\n\\n## EXPERIÊNCIA\\n\\n- Curso Extracurricular de Clojure em progresso (Curso NuFuturo)\\n\\n## HABILIDADES TÉCNICAS\\n\\n- Java\\n- Python\\n- Git e Github\\n- JUnit5\\n- Inglês Fluente\\n\\n## OUTRAS HABILIDADES\\n\\n- Trabalho em equipe\\n- Boa comunicação\\n- Proatividade e dedicação em busca do aprendizado\\n- Adaptabilidade\\n- Resolução de problemas\\n\\n<!-- image -->', 'Currículo - Joâo Victor': \"## João Victor de Macedo Silva\\n\\n## Detalhes Pessoais\\n\\nTelefone:\\n\\n+55 (83) 99623-6656\\n\\nE-mail:\\n\\njoaovmacedo02@gmail.com\\n\\nLinkedIn:\\n\\nhttps://www.linkedin.com/in/jvmacedos/\\n\\nPortfólio:\\n\\ngithub.com/jvmacedos\\n\\n## Objetivo\\n\\nAtuar nas áreas de Análise, Ciência ou Engenharia de Dados, aplicando conhecimentos em SQL, Python, Power BI e Google Cloud para gerar insights estratégicos e apoiar a tomada de decisões.\\n\\n## Resumo Profissional\\n\\nGraduado  em  Sistemas  de  Informação  com sólida formação prática em análise e ciência  de  dados.  Experiência  comprovada  na  criação  de  dashboards  em  Power  BI, tratamento de dados com SQL e Python, e uso da Google Cloud Platform. Atuando como estagiário  de  dados,  realizei  soluções  de  BI  para  melhorar  a  performance  de  análises estratégicas.\\n\\n## Experiências Profissionais\\n\\nEstágio em Análise de Dados - Impulse Business (Out/2024 - Jun/2024)\\n\\n- -Criação e estilização de dashboards no Power BI.\\n- -Tratamento de dados em Excel, SQL e outras fontes.\\n- -Desenvolvimento de consultas SQL otimizadas.\\n- -Criação de métricas (KPI's) conforme necessidades dos clientes.\\n- -Implantação de automações para atualização de dados.\\n- -Documentação técnica de projetos.\\n- -Contato direto com clientes para levantamento de requisitos.\\n\\n## Formação\\n\\nGraduação em Sistemas de Informação - Unifacisa\\n\\nStatus: Concluído em Jun/2025\\n\\n## Idiomas\\n\\n## Inglês Avançado (Cultura Inglesa - Campina Grande)\\n\\n- -Capaz de ler documentação técnica, comunicar-se e participar de reuniões em inglês.\\n\\n## Espanhol Intermediário\\n\\n- -Capaz de ler e comunicar-se.\\n\\n## Habilidades\\n\\n## Hard Skills:\\n\\n- -Programação: Python, Java, JavaScript\\n- -SQL e NoSQL\\n- -Power BI (Dashboards, KPIs e análise de dados)\\n- -Google Cloud Platform (BigQuery, Machine Learning e visualização de dados)\\n- -Desenvolvimento Web básico\\n- -Excel para Análise de Dados\\n\\n## Metodologias e Soft Skills:\\n\\n- -Métodos Ágeis (SCRUM, Kanban)\\n- -Documentação Técnica\\n\\n## Certificações\\n\\n## Google Cloud e BigQuery:\\n\\nAchieving Advanced Insights with BigQuery - Coursera Exploring and Preparing Your Data with BigQuery - Coursera Creating New BigQuery Datasets and Visualizing Insights - Coursera Applying Machine Learning to Your Data with GCP - Coursera\\n\\n## Ciência de Dados:\\n\\nPython for Data Science, AI &amp; Development - Coursera\\n\\nTools for Data Science - Coursera\\n\\nWhat is Data Science? - Coursera\\n\\nData Science Methodology - Coursera\\n\\nSantander Bootcamp 2023 (Ciência de Dados com Python) - Santander Universidades Brasil\\n\\n## Metodologias e Soft Skills:\\n\\nEnterprise Design Thinking Practitioner - IBM\\n\\nScrum Fundamentals Certified (SFC) - SCRUMstudy\", 'Currículo - Lucas Larry': '## Lucas Larry Tertuliano Oliveira dos Santos\\n\\nQA | Desenvolvedor\\n\\n## CONTATO:\\n\\n- Email: lucasslarryy@gmail.com\\n\\n- Telefone: (83) 99819 3024\\n\\n- Cidade: Campina Grande - PB\\n\\n- LinkedIn: https://www.linkedin.com/in/lucaslarry\\n\\n- GitHub: https://github.com/lucaslarry\\n\\n## SOBRE MIM:\\n\\n<!-- image -->\\n\\n- Sou um desenvolvedor com especialização em Quality Engineering focado em garantir a qualidade e eficiência no desenvolvimento de software. Possuo experiência em automação de testes para aplicações web e APIs, utilizando ferramentas como Selenium e Rest Assured. Além disso, tenho conhecimentos em Java, Spring Boot e JavaScript, Node para desenvolvimento fullstack, sempre buscando aprimorar minhas habilidades e contribuir para a entrega de software robusto e confiável.\\n\\n## FORMAÇÃO ACADÊMICA\\n\\n- Sistemas de Informação na Unifacisa - Novembro de 2022 - Presente\\n\\n## EXPERIÊNCIA PROFISSIONAL\\n\\n## Analista de Testes - GetNet\\n\\n- Atuo na validação de fluxos de usuário em aplicações internas, garantindo a qualidade das entregas através de testes funcionais. Responsável por planejar, executar e documentar os testes, identificando falhas e contribuindo para a melhoria contínua dos produtos.\\n\\n## QA Intern - DBC Company\\n\\n- Participei da trilha Vem Ser 15, desenvolvendo habilidades em testes de software, automação (REST Assured, Selenium e Cypress)  e práticas de DevOps.\\n- Atuei em projetos reais como QA, contribuindo para a definição de critérios de aceite, automação de pipeline com github actions e execução de testes de API e web.\\n- Também participei de uma formação fullstack com foco em desenvolvimento backend utilizando Spring Boot, Spring Data JPA, Spring Security e Swagger.\\n\\n## PROJETOS\\n\\n## Api Gerenciamento de pedidos\\n\\n- Criei uma API em Spring Boot de um sistema de gerenciamento de pedidos e pagamentos. O projeto utiliza Spring Data JPA para persistência, Spring Security para autenticação e autorização, e Swagger para documentação da API.', 'Currículo - Pedro Mélo': '## PEDRO   HENRIQUE   DE   FREITAS   MÉLO\\n\\n## DESENVOLVEDOR FULLSTACK\\n\\n## CONTATO\\n\\n- Email: pedrohenriquefm20023@gmail.com\\n\\n- Phone: (83) 99602-4859\\n\\n- Address: Rua Salvino de Oliveira Neto, 640, Campina Grande - PB\\n\\n- Github: github.com/pedrohdfm\\n\\n- LinkedIn: linkedin.com/in/pedro-freitas-51211421b/\\n\\n## OBJETIVO\\n\\n- Sou um desenvolvedor FullStack com base sólida em Java (Spring Boot, arquitetura MVC) e tecnologias do MERN(Mongo, Express, React e Node.js) stack. Apaixonado por resolver problemas complexos e fornecer soluções de software de alta qualidade e ansioso para aproveitar minha base técnica e habilidades de resolução de problemas para contribuir com equipes de desenvolvimento de software inovadoras. Além disso, sou entusiasta da área de Cibersegurança e mais especificamente do Pentesting e Bug Bounty.\\n\\n## HABILIDADES TÉCNICAS\\n\\n- Backend: Java (Spring Boot), Node.js, Express.js, RESTful APIs;\\n- Frontend: React.js, HTML5, CSS3, JavaScript;\\n- Bancos de Dados: MongoDB (Schema Design, Aggregation), MySQL (JDBC);\\n- Ferramentas: Git/GitHub, metodologias ágeis (Scrum, Kanban), Postman, Burp Suite, Nmap, BPMN;\\n- Linux Básico;\\n\\n## PROJETOS PESSOAIS\\n\\n- Projeto de aplicação web para gerenciamento de banca de poker, com criação de usuários, login, adicionar torneios e obter dados estatísticos de ROI, ITM (In the money), lucro e prejuízo. Foi utilizado o stack MERN (MongoDB, Express.js, React e Node.js), autenticação com JWT, API test com Postman.\\n- Projeto de comércio eletrônico em Java usando a arquitetura MVC com as funcionalidades de criação, listagem, exclusão e atualização de produtos e persistência de dados com a API JDBC e o banco de dados MySQL.\\n\\n## FORMAÇÃO\\n\\n- Bacharelado em Sistemas de Informação\\n- UniFacisa, 2022 - 2026 (Esperado) | Status: Em andamento\\n\\n## IDIOMAS\\n\\n- Português - Nativo\\n- Inglês - Avançado.'}\n",
            "Iniciando a análise dos currículos...\n",
            "\n",
            "Analisando currículo: curr_0\n",
            "Resultado para curr_0: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "\n",
            "Analisando currículo: curr_1\n",
            "Resultado para curr_1: {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados']}\n",
            "\n",
            "Analisando currículo: curr_2\n",
            "Resultado para curr_2: {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "\n",
            "Analisando currículo: curr_3\n",
            "Resultado para curr_3: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Product Owner']}\n",
            "\n",
            "Analisando currículo: curr_4\n",
            "Resultado para curr_4: {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "\n",
            "Analisando currículo: curr_5\n",
            "Resultado para curr_5: {'habilidades': ['Selenium', 'Cypress', 'Jenkins'], 'idiomas': [], 'cargo': ['Analista de QA', 'Analista de QA Junior']}\n",
            "\n",
            "Analisando currículo: curr_6\n",
            "Resultado para curr_6: {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end']}\n",
            "\n",
            "Analisando currículo: curr_7\n",
            "Resultado para curr_7: {'habilidades': ['Scrum', 'Kanban', 'JIRA'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Gerente de Projetos', 'Gerente de Projetos Junior']}\n",
            "\n",
            "Analisando currículo: curr_8\n",
            "Resultado para curr_8: {'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Full Stack']}\n",
            "\n",
            "Analisando currículo: curr_9\n",
            "Resultado para curr_9: {'habilidades': ['Power BI', 'Excel', 'Python', 'SQL'], 'idiomas': [], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_10\n",
            "Resultado para curr_10: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Espanhol'], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_11\n",
            "Resultado para curr_11: {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados']}\n",
            "\n",
            "Analisando currículo: curr_12\n",
            "Resultado para curr_12: {'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_13\n",
            "Resultado para curr_13: {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "\n",
            "Analisando currículo: curr_14\n",
            "Resultado para curr_14: {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}\n",
            "\n",
            "Analisando currículo: curr_15\n",
            "Resultado para curr_15: {'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Software']}\n",
            "\n",
            "Analisando currículo: curr_16\n",
            "Resultado para curr_16: {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS', 'Scrum', 'Kanban'], 'idiomas': [], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "\n",
            "Analisando currículo: curr_17\n",
            "Resultado para curr_17: {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Front-end']}\n",
            "\n",
            "Analisando currículo: curr_18\n",
            "Resultado para curr_18: {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "\n",
            "Analisando currículo: curr_19\n",
            "Resultado para curr_19: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "\n",
            "Analisando currículo: curr_20\n",
            "Resultado para curr_20: {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados', 'Engenheiro de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_21\n",
            "Resultado para curr_21: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Product Owner']}\n",
            "\n",
            "Analisando currículo: curr_22\n",
            "Resultado para curr_22: {'habilidades': ['Redes', 'Linux', 'Scripting Bash', 'ITIL'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Suporte', 'Analista de Suporte Junior']}\n",
            "\n",
            "Analisando currículo: curr_23\n",
            "Resultado para curr_23: {'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_24\n",
            "Resultado para curr_24: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados']}\n",
            "\n",
            "Analisando currículo: curr_25\n",
            "Resultado para curr_25: {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': [], 'cargo': ['Desenvolvedor Mobile']}\n",
            "\n",
            "Analisando currículo: curr_26\n",
            "Resultado para curr_26: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados']}\n",
            "\n",
            "Analisando currículo: curr_27\n",
            "Resultado para curr_27: {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': [], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "\n",
            "Analisando currículo: curr_28\n",
            "Resultado para curr_28: {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': [], 'cargo': ['Desenvolvedor Mobile']}\n",
            "\n",
            "Analisando currículo: curr_29\n",
            "Resultado para curr_29: {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Back-end']}\n",
            "\n",
            "Analisando currículo: curr_30\n",
            "Resultado para curr_30: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "\n",
            "Analisando currículo: curr_31\n",
            "Resultado para curr_31: {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end', 'Desenvolvedor Back-end Junior']}\n",
            "\n",
            "Analisando currículo: curr_32\n",
            "Resultado para curr_32: {'habilidades': ['Python', 'SQL', 'Power BI', 'Excel'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_33\n",
            "Resultado para curr_33: {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português'], 'cargo': ['Engenheiro de Dados']}\n",
            "\n",
            "Analisando currículo: curr_34\n",
            "Resultado para curr_34: {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "\n",
            "Analisando currículo: curr_35\n",
            "Resultado para curr_35: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados']}\n",
            "\n",
            "Analisando currículo: curr_36\n",
            "Resultado para curr_36: {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "\n",
            "Analisando currículo: curr_37\n",
            "Resultado para curr_37: {'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_38\n",
            "Resultado para curr_38: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_39\n",
            "Resultado para curr_39: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "\n",
            "Analisando currículo: curr_40\n",
            "Resultado para curr_40: {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}\n",
            "\n",
            "Analisando currículo: curr_41\n",
            "Resultado para curr_41: {'habilidades': ['Selenium', 'Cypress', 'Jenkins', 'Scrum/Kanban'], 'idiomas': [], 'cargo': ['Analista de QA']}\n",
            "\n",
            "Analisando currículo: curr_42\n",
            "Resultado para curr_42: {'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Full Stack', 'Desenvolvedor Full Stack Junior']}\n",
            "\n",
            "Analisando currículo: curr_43\n",
            "Resultado para curr_43: {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Back-end']}\n",
            "\n",
            "Analisando currículo: curr_44\n",
            "Resultado para curr_44: {'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Software']}\n",
            "\n",
            "Analisando currículo: curr_45\n",
            "Resultado para curr_45: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_46\n",
            "Resultado para curr_46: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "\n",
            "Analisando currículo: curr_47\n",
            "Resultado para curr_47: {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': [], 'cargo': ['Engenheira de Dados']}\n",
            "\n",
            "Analisando currículo: curr_48\n",
            "Resultado para curr_48: {'habilidades': ['Selenium', 'Cypress', 'Jenkins'], 'idiomas': [], 'cargo': ['Analista de QA']}\n",
            "\n",
            "Analisando currículo: curr_49\n",
            "Resultado para curr_49: {'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': [], 'cargo': ['Desenvolvedor Full Stack']}\n",
            "\n",
            "Analisando currículo: curr_50\n",
            "Resultado para curr_50: {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner']}\n",
            "\n",
            "Analisando currículo: curr_51\n",
            "Resultado para curr_51: {'habilidades': ['Python', 'SQL', 'Power BI', 'Excel', 'Scrum', 'Kanban'], 'idiomas': ['Português'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "\n",
            "Analisando currículo: curr_52\n",
            "Resultado para curr_52: {'habilidades': ['Kotlin', 'Java', 'Android SDK', 'REST APIs'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedora Android', 'Desenvolvedora Android Junior']}\n",
            "\n",
            "Analisando currículo: curr_53\n",
            "Resultado para curr_53: {'habilidades': ['JavaScript', 'React', 'TypeScript', 'CSS'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "\n",
            "Analisando currículo: curr_54\n",
            "Resultado para curr_54: {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados']}\n",
            "\n",
            "Analisando currículo: curr_55\n",
            "Resultado para curr_55: {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end', 'Desenvolvedor Back-end Junior']}\n",
            "\n",
            "Analisando currículo: curr_56\n",
            "Resultado para curr_56: {'habilidades': ['Linux', 'Redes', 'Scripting Bash', 'ITIL'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Suporte', 'Analista de Suporte Junior']}\n",
            "\n",
            "Analisando currículo: curr_57\n",
            "Resultado para curr_57: {'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheira de Software', 'Engenheira de Software Junior']}\n",
            "\n",
            "Analisando currículo: curr_58\n",
            "Resultado para curr_58: {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}\n",
            "\n",
            "Analisando currículo: curr_59\n",
            "Resultado para curr_59: {'habilidades': ['Scrum', 'Kanban', 'JIRA'], 'idiomas': [], 'cargo': ['Gerente de Projetos', 'Gerente de Projetos Junior']}\n",
            "\n",
            "Analisando currículo: curr_60\n",
            "Resultado para curr_60: {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "\n",
            "Analisando currículo: curr_61\n",
            "Resultado para curr_61: {'habilidades': ['Apex', 'Flows', 'Lightning Web Components', 'SOQL', 'SOSL', 'OmniScript', 'DataRaptors', 'Integration Procedures', 'FlexCards', 'Industries CPQ', 'APIs REST & SOAP', 'Connected Apps', 'Named Credentials'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Salesforce Sênior']}\n",
            "\n",
            "Analisando currículo: curr_62\n",
            "Resultado para curr_62: {'habilidades': ['JavaScript', 'TypeScript', 'HTML', 'CSS', 'React', 'React Native', 'Next.js', 'Flutter', 'Styled-Components', 'Bootstrap', 'Tailwind CSS', 'MongoDB', 'PostgreSQL'], 'idiomas': ['Português', 'Inglês', 'Japonês'], 'cargo': ['Desenvolvedor Front-end']}\n",
            "\n",
            "Analisando currículo: curr_63\n",
            "Resultado para curr_63: {'habilidades': ['Java', 'Python', 'Git', 'Github', 'JUnit5'], 'idiomas': ['Português', 'Inglês'], 'cargo': []}\n",
            "\n",
            "Analisando currículo: curr_64\n",
            "Resultado para curr_64: {'habilidades': ['SQL', 'Python', 'Power BI', 'Google Cloud', 'GitHub'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Estagiário em Análise de Dados']}\n",
            "\n",
            "Analisando currículo: curr_65\n",
            "Resultado para curr_65: {'habilidades': ['Java', 'Spring Boot', 'JavaScript', 'Node', 'Selenium', 'Rest Assured'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Testes']}\n",
            "\n",
            "Analisando currículo: curr_66\n",
            "Resultado para curr_66: {'habilidades': ['Java', 'Spring Boot', 'MVC', 'MongoDB', 'Express.js', 'RESTful APIs', 'React.js', 'HTML5', 'CSS3', 'JavaScript', 'Node.js', 'MySQL', 'JDBC'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DESENVOLVEDOR FULLSTACK']}\n",
            "\n",
            "Análise concluída.\n",
            "{'curr_0': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}, 'curr_1': {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados']}, 'curr_2': {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}, 'curr_3': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Product Owner']}, 'curr_4': {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}, 'curr_5': {'habilidades': ['Selenium', 'Cypress', 'Jenkins'], 'idiomas': [], 'cargo': ['Analista de QA', 'Analista de QA Junior']}, 'curr_6': {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end']}, 'curr_7': {'habilidades': ['Scrum', 'Kanban', 'JIRA'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Gerente de Projetos', 'Gerente de Projetos Junior']}, 'curr_8': {'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Full Stack']}, 'curr_9': {'habilidades': ['Power BI', 'Excel', 'Python', 'SQL'], 'idiomas': [], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}, 'curr_10': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Espanhol'], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}, 'curr_11': {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados']}, 'curr_12': {'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}, 'curr_13': {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}, 'curr_14': {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}, 'curr_15': {'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Software']}, 'curr_16': {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS', 'Scrum', 'Kanban'], 'idiomas': [], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}, 'curr_17': {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Front-end']}, 'curr_18': {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}, 'curr_19': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}, 'curr_20': {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados', 'Engenheiro de Dados Junior']}, 'curr_21': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Product Owner']}, 'curr_22': {'habilidades': ['Redes', 'Linux', 'Scripting Bash', 'ITIL'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Suporte', 'Analista de Suporte Junior']}, 'curr_23': {'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}, 'curr_24': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados']}, 'curr_25': {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': [], 'cargo': ['Desenvolvedor Mobile']}, 'curr_26': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados']}, 'curr_27': {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': [], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}, 'curr_28': {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': [], 'cargo': ['Desenvolvedor Mobile']}, 'curr_29': {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Back-end']}, 'curr_30': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}, 'curr_31': {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end', 'Desenvolvedor Back-end Junior']}, 'curr_32': {'habilidades': ['Python', 'SQL', 'Power BI', 'Excel'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}, 'curr_33': {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português'], 'cargo': ['Engenheiro de Dados']}, 'curr_34': {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}, 'curr_35': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados']}, 'curr_36': {'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}, 'curr_37': {'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}, 'curr_38': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}, 'curr_39': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}, 'curr_40': {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}, 'curr_41': {'habilidades': ['Selenium', 'Cypress', 'Jenkins', 'Scrum/Kanban'], 'idiomas': [], 'cargo': ['Analista de QA']}, 'curr_42': {'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Full Stack', 'Desenvolvedor Full Stack Junior']}, 'curr_43': {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Back-end']}, 'curr_44': {'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Software']}, 'curr_45': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}, 'curr_46': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}, 'curr_47': {'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': [], 'cargo': ['Engenheira de Dados']}, 'curr_48': {'habilidades': ['Selenium', 'Cypress', 'Jenkins'], 'idiomas': [], 'cargo': ['Analista de QA']}, 'curr_49': {'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': [], 'cargo': ['Desenvolvedor Full Stack']}, 'curr_50': {'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner']}, 'curr_51': {'habilidades': ['Python', 'SQL', 'Power BI', 'Excel', 'Scrum', 'Kanban'], 'idiomas': ['Português'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}, 'curr_52': {'habilidades': ['Kotlin', 'Java', 'Android SDK', 'REST APIs'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedora Android', 'Desenvolvedora Android Junior']}, 'curr_53': {'habilidades': ['JavaScript', 'React', 'TypeScript', 'CSS'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}, 'curr_54': {'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados']}, 'curr_55': {'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end', 'Desenvolvedor Back-end Junior']}, 'curr_56': {'habilidades': ['Linux', 'Redes', 'Scripting Bash', 'ITIL'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Suporte', 'Analista de Suporte Junior']}, 'curr_57': {'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheira de Software', 'Engenheira de Software Junior']}, 'curr_58': {'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}, 'curr_59': {'habilidades': ['Scrum', 'Kanban', 'JIRA'], 'idiomas': [], 'cargo': ['Gerente de Projetos', 'Gerente de Projetos Junior']}, 'curr_60': {'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}, 'curr_61': {'habilidades': ['Apex', 'Flows', 'Lightning Web Components', 'SOQL', 'SOSL', 'OmniScript', 'DataRaptors', 'Integration Procedures', 'FlexCards', 'Industries CPQ', 'APIs REST & SOAP', 'Connected Apps', 'Named Credentials'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Salesforce Sênior']}, 'curr_62': {'habilidades': ['JavaScript', 'TypeScript', 'HTML', 'CSS', 'React', 'React Native', 'Next.js', 'Flutter', 'Styled-Components', 'Bootstrap', 'Tailwind CSS', 'MongoDB', 'PostgreSQL'], 'idiomas': ['Português', 'Inglês', 'Japonês'], 'cargo': ['Desenvolvedor Front-end']}, 'curr_63': {'habilidades': ['Java', 'Python', 'Git', 'Github', 'JUnit5'], 'idiomas': ['Português', 'Inglês'], 'cargo': []}, 'curr_64': {'habilidades': ['SQL', 'Python', 'Power BI', 'Google Cloud', 'GitHub'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Estagiário em Análise de Dados']}, 'curr_65': {'habilidades': ['Java', 'Spring Boot', 'JavaScript', 'Node', 'Selenium', 'Rest Assured'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Testes']}, 'curr_66': {'habilidades': ['Java', 'Spring Boot', 'MVC', 'MongoDB', 'Express.js', 'RESTful APIs', 'React.js', 'HTML5', 'CSS3', 'JavaScript', 'Node.js', 'MySQL', 'JDBC'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DESENVOLVEDOR FULLSTACK']}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Cálculos de similaridade"
      ],
      "metadata": {
        "id": "HPVoo8pP6_cq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálculo de similaridade especialista para cargo"
      ],
      "metadata": {
        "id": "R_N7jVZ4sbNW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from sentence_transformers import util\n",
        "\n",
        "def calcular_similaridade_cargos(cargo_desejado: str, cargo_cv: str, embedding_model) -> float:\n",
        "    embedding_desejado = torch.tensor(embedding_model.embed_query(cargo_desejado))\n",
        "    embedding_cv = torch.tensor(embedding_model.embed_query(cargo_cv))\n",
        "\n",
        "    similaridade = util.cos_sim(embedding_desejado, embedding_cv)\n",
        "    score = similaridade.item()\n",
        "\n",
        "    # Normalizando\n",
        "    return max(0, score)"
      ],
      "metadata": {
        "id": "RgGqibuYFXyJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálculo de similaridade especialista para habilidades"
      ],
      "metadata": {
        "id": "JhlrVtCvse_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_score_habilidades_hibrido(\n",
        "    habilidades_desejadas: list,\n",
        "    habilidades_cv: list,\n",
        "    embedding_model,\n",
        "    bonus_semantico: float = 0.75\n",
        ") -> float:\n",
        "    \"\"\"\n",
        "    Calcula o score de habilidades usando uma abordagem híbrida:\n",
        "    1. Procura por correspondência exata (score 1.0).\n",
        "    2. Se não encontrar, calcula a similaridade semântica e aplica um bônus (score < 1.0).\n",
        "    \"\"\"\n",
        "\n",
        "    habilidades_desejadas = habilidades_desejadas.split(',')\n",
        "    if not habilidades_desejadas:\n",
        "        return 1.0 # Se nenhuma habilidade é pedida, o requisito é 100% atendido\n",
        "    if not habilidades_cv:\n",
        "        return 0.0 # Se o CV não tem habilidades, a pontuação é 0\n",
        "\n",
        "    scores_individuais = []\n",
        "\n",
        "    habilidades_cv_lower_set = {skill.lower() for skill in habilidades_cv}\n",
        "\n",
        "    embeddings_cv = embedding_model.embed_documents(list(habilidades_cv_lower_set))\n",
        "\n",
        "    for skill_desejada in habilidades_desejadas:\n",
        "        skill_desejada_lower = skill_desejada.lower()\n",
        "\n",
        "\n",
        "        # VERIFICA CORRESPONDÊNCIA EXATA\n",
        "        if skill_desejada_lower in habilidades_cv_lower_set:\n",
        "            scores_individuais.append(1.0)\n",
        "            continue\n",
        "\n",
        "        # CALCULA SIMILARIDADE SEMÂNTICA\n",
        "\n",
        "        embedding_desejado = embedding_model.embed_query(skill_desejada_lower)\n",
        "\n",
        "        similaridades = util.cos_sim(embedding_desejado, embeddings_cv)\n",
        "        melhor_similaridade = torch.max(similaridades).item()\n",
        "\n",
        "        score_semantico = melhor_similaridade * bonus_semantico\n",
        "        scores_individuais.append(score_semantico)\n",
        "\n",
        "    score_final = sum(scores_individuais) / len(scores_individuais)\n",
        "    return score_final"
      ],
      "metadata": {
        "id": "Dcj-xPqc7BYq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cálculo do score total"
      ],
      "metadata": {
        "id": "Zp6SlUuFsh3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calcular_score_final(curriculo_analisado: dict, input_usuario: dict, pesos: dict, embedding_model) -> dict:\n",
        "\n",
        "    habilidades_desejadas = input_usuario.get('habilidades', [])\n",
        "    habilidades_cv = curriculo_analisado.get('habilidades', [])\n",
        "    score_habilidades = calcular_score_habilidades_hibrido(\n",
        "        habilidades_desejadas,\n",
        "        habilidades_cv,\n",
        "        embedding_model\n",
        "    )\n",
        "\n",
        "    idiomas_desejados = [lang.lower() for lang in input_usuario.get('idiomas', []).split(',')]\n",
        "    idiomas_cv_str = \" \".join(curriculo_analisado.get('idiomas', [])).lower()\n",
        "    idiomas_encontrados = sum(1 for lang in idiomas_desejados if lang in idiomas_cv_str)\n",
        "    score_idiomas = idiomas_encontrados / len(idiomas_desejados) if idiomas_desejados else 1.0\n",
        "\n",
        "    cargo_desejado = input_usuario.get('cargo')\n",
        "    cargo_cv = curriculo_analisado.get('cargo', [\"\"])[0] if curriculo_analisado.get('cargo') else \"\"\n",
        "\n",
        "    score_cargo = 0.0\n",
        "    if cargo_desejado and cargo_cv:\n",
        "\n",
        "        score_cargo = calcular_similaridade_cargos(cargo_desejado, cargo_cv, embedding_model)\n",
        "\n",
        "    score_total = (pesos['habilidades'] * score_habilidades) + \\\n",
        "                  (pesos['idiomas'] * score_idiomas) + \\\n",
        "                  (pesos['cargo'] * score_cargo)\n",
        "\n",
        "    return {\n",
        "        'habilidades': score_habilidades,\n",
        "        'idiomas': score_idiomas,\n",
        "        'cargo': score_cargo,\n",
        "        'total': score_total\n",
        "    }"
      ],
      "metadata": {
        "id": "ju_0j7vQETh6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Célula para testes de scores e aptidão da análise:"
      ],
      "metadata": {
        "id": "kBVc8zR0mx0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pesos = {\n",
        "  \"habilidades\": 0.5,\n",
        "  \"idiomas\": 0.3,\n",
        "  \"cargo\": 0.2\n",
        "}\n",
        "\n",
        "curriculos_scores = {}\n",
        "\n",
        "# print(f\"INPUTS DO RH: '{input_rh}\")\n",
        "\n",
        "# score_final = calcular_score_final(curriculos_analisados[\"curr_2\"], input_rh, pesos, embedding_model)\n",
        "# print(f\"SCORE FINAL: '{score_final}'\")\n",
        "\n",
        "for cid, curriculo_analisado in curriculos_analisados.items():\n",
        "  print(curriculo_analisado)\n",
        "  score_final = calcular_score_final(curriculo_analisado, input_rh, pesos, embedding_model)\n",
        "  curriculos_scores[cid] = score_final\n",
        "\n",
        "print(f\"CURRICULOS_SCORES: '{curriculos_scores}'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_SJkjiV1IXN6",
        "outputId": "e0b40864-c427-4832-fc1f-62b927cc0fe0"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "{'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados']}\n",
            "{'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Product Owner']}\n",
            "{'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "{'habilidades': ['Selenium', 'Cypress', 'Jenkins'], 'idiomas': [], 'cargo': ['Analista de QA', 'Analista de QA Junior']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end']}\n",
            "{'habilidades': ['Scrum', 'Kanban', 'JIRA'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Gerente de Projetos', 'Gerente de Projetos Junior']}\n",
            "{'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Full Stack']}\n",
            "{'habilidades': ['Power BI', 'Excel', 'Python', 'SQL'], 'idiomas': [], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Espanhol'], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}\n",
            "{'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados']}\n",
            "{'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "{'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "{'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}\n",
            "{'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Software']}\n",
            "{'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS', 'Scrum', 'Kanban'], 'idiomas': [], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "{'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Front-end']}\n",
            "{'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "{'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Dados', 'Engenheiro de Dados Junior']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Product Owner']}\n",
            "{'habilidades': ['Redes', 'Linux', 'Scripting Bash', 'ITIL'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Suporte', 'Analista de Suporte Junior']}\n",
            "{'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados']}\n",
            "{'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': [], 'cargo': ['Desenvolvedor Mobile']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados']}\n",
            "{'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': [], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "{'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': [], 'cargo': ['Desenvolvedor Mobile']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Back-end']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end', 'Desenvolvedor Back-end Junior']}\n",
            "{'habilidades': ['Python', 'SQL', 'Power BI', 'Excel'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "{'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': ['Português'], 'cargo': ['Engenheiro de Dados']}\n",
            "{'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados']}\n",
            "{'habilidades': ['JavaScript', 'React', 'Vue.js', 'CSS'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "{'habilidades': ['SQL', 'Power BI', 'Excel', 'Python'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "{'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}\n",
            "{'habilidades': ['Selenium', 'Cypress', 'Jenkins', 'Scrum/Kanban'], 'idiomas': [], 'cargo': ['Analista de QA']}\n",
            "{'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Full Stack', 'Desenvolvedor Full Stack Junior']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Back-end']}\n",
            "{'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheiro de Software']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Cientista de Dados', 'Cientista de Dados Junior']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner', 'Product Owner Junior']}\n",
            "{'habilidades': ['Python', 'SQL', 'Spark', 'Hadoop'], 'idiomas': [], 'cargo': ['Engenheira de Dados']}\n",
            "{'habilidades': ['Selenium', 'Cypress', 'Jenkins'], 'idiomas': [], 'cargo': ['Analista de QA']}\n",
            "{'habilidades': ['Node.js', 'React', 'MongoDB', 'GraphQL'], 'idiomas': [], 'cargo': ['Desenvolvedor Full Stack']}\n",
            "{'habilidades': ['Roadmapping', 'User Stories', 'Scrum', 'Analytics'], 'idiomas': [], 'cargo': ['Product Owner']}\n",
            "{'habilidades': ['Python', 'SQL', 'Power BI', 'Excel', 'Scrum', 'Kanban'], 'idiomas': ['Português'], 'cargo': ['Analista de Dados', 'Analista de Dados Junior']}\n",
            "{'habilidades': ['Kotlin', 'Java', 'Android SDK', 'REST APIs'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedora Android', 'Desenvolvedora Android Junior']}\n",
            "{'habilidades': ['JavaScript', 'React', 'TypeScript', 'CSS'], 'idiomas': ['Português'], 'cargo': ['Desenvolvedor Front-end', 'Desenvolvedor Front-end Junior']}\n",
            "{'habilidades': ['Python', 'Pandas', 'Scikit-learn', 'TensorFlow'], 'idiomas': [], 'cargo': ['Cientista de Dados']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'SQL', 'Docker'], 'idiomas': [], 'cargo': ['Desenvolvedor Back-end', 'Desenvolvedor Back-end Junior']}\n",
            "{'habilidades': ['Linux', 'Redes', 'Scripting Bash', 'ITIL'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Suporte', 'Analista de Suporte Junior']}\n",
            "{'habilidades': ['C#', '.NET', 'Azure', 'SQL Server'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Engenheira de Software', 'Engenheira de Software Junior']}\n",
            "{'habilidades': ['Kotlin', 'Swift', 'React Native', 'Firebase'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Mobile', 'Desenvolvedor Mobile Junior']}\n",
            "{'habilidades': ['Scrum', 'Kanban', 'JIRA'], 'idiomas': [], 'cargo': ['Gerente de Projetos', 'Gerente de Projetos Junior']}\n",
            "{'habilidades': ['AWS', 'Docker', 'Kubernetes', 'Terraform'], 'idiomas': [], 'cargo': ['DevOps Engineer', 'DevOps Engineer Junior']}\n",
            "{'habilidades': ['Apex', 'Flows', 'Lightning Web Components', 'SOQL', 'SOSL', 'OmniScript', 'DataRaptors', 'Integration Procedures', 'FlexCards', 'Industries CPQ', 'APIs REST & SOAP', 'Connected Apps', 'Named Credentials'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Desenvolvedor Salesforce Sênior']}\n",
            "{'habilidades': ['JavaScript', 'TypeScript', 'HTML', 'CSS', 'React', 'React Native', 'Next.js', 'Flutter', 'Styled-Components', 'Bootstrap', 'Tailwind CSS', 'MongoDB', 'PostgreSQL'], 'idiomas': ['Português', 'Inglês', 'Japonês'], 'cargo': ['Desenvolvedor Front-end']}\n",
            "{'habilidades': ['Java', 'Python', 'Git', 'Github', 'JUnit5'], 'idiomas': ['Português', 'Inglês'], 'cargo': []}\n",
            "{'habilidades': ['SQL', 'Python', 'Power BI', 'Google Cloud', 'GitHub'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Estagiário em Análise de Dados']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'JavaScript', 'Node', 'Selenium', 'Rest Assured'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['Analista de Testes']}\n",
            "{'habilidades': ['Java', 'Spring Boot', 'MVC', 'MongoDB', 'Express.js', 'RESTful APIs', 'React.js', 'HTML5', 'CSS3', 'JavaScript', 'Node.js', 'MySQL', 'JDBC'], 'idiomas': ['Português', 'Inglês'], 'cargo': ['DESENVOLVEDOR FULLSTACK']}\n",
            "CURRICULOS_SCORES: '{'curr_0': {'habilidades': 0.4697190076112747, 'idiomas': 0.0, 'cargo': 0.4733961820602417, 'total': 0.3295387402176857}, 'curr_1': {'habilidades': 0.4089803360402584, 'idiomas': 1.0, 'cargo': 0.5357565879821777, 'total': 0.6116414856165648}, 'curr_2': {'habilidades': 0.5366339478641748, 'idiomas': 1.0, 'cargo': 0.42701438069343567, 'total': 0.6537198500707746}, 'curr_3': {'habilidades': 0.4697190076112747, 'idiomas': 1.0, 'cargo': 0.4733961820602417, 'total': 0.6295387402176857}, 'curr_4': {'habilidades': 0.5366339478641748, 'idiomas': 0.0, 'cargo': 0.42701438069343567, 'total': 0.35371985007077456}, 'curr_5': {'habilidades': 0.40705761685967445, 'idiomas': 0.0, 'cargo': 0.3662010729312897, 'total': 0.2767690230160952}, 'curr_6': {'habilidades': 0.7328115403652191, 'idiomas': 0.0, 'cargo': 0.42307958006858826, 'total': 0.4510216861963272}, 'curr_7': {'habilidades': 0.5791685748845339, 'idiomas': 1.0, 'cargo': 0.5836670398712158, 'total': 0.7063176954165101}, 'curr_8': {'habilidades': 0.33792024850845337, 'idiomas': 0.5, 'cargo': 0.3052271902561188, 'total': 0.38000556230545046}, 'curr_9': {'habilidades': 0.22559828124940395, 'idiomas': 0.0, 'cargo': 0.4522070586681366, 'total': 0.2032405523583293}, 'curr_10': {'habilidades': 0.24254637211561203, 'idiomas': 0.5, 'cargo': 0.40914157032966614, 'total': 0.35310150012373925}, 'curr_11': {'habilidades': 0.4089803360402584, 'idiomas': 1.0, 'cargo': 0.5357565879821777, 'total': 0.6116414856165648}, 'curr_12': {'habilidades': 0.22559828124940395, 'idiomas': 1.0, 'cargo': 0.4522070586681366, 'total': 0.5032405523583293}, 'curr_13': {'habilidades': 0.5366339478641748, 'idiomas': 0.0, 'cargo': 0.42701438069343567, 'total': 0.35371985007077456}, 'curr_14': {'habilidades': 0.46507314406335354, 'idiomas': 1.0, 'cargo': 0.47156286239624023, 'total': 0.6268491445109249}, 'curr_15': {'habilidades': 0.42361604422330856, 'idiomas': 1.0, 'cargo': 0.8110970258712769, 'total': 0.6740274272859097}, 'curr_16': {'habilidades': 0.5057445112615824, 'idiomas': 0.0, 'cargo': 0.4358314871788025, 'total': 0.3400385530665517}, 'curr_17': {'habilidades': 0.3439495414495468, 'idiomas': 1.0, 'cargo': 0.4358314871788025, 'total': 0.5591410681605339}, 'curr_18': {'habilidades': 0.5366339478641748, 'idiomas': 0.0, 'cargo': 0.42701438069343567, 'total': 0.35371985007077456}, 'curr_19': {'habilidades': 0.4697190076112747, 'idiomas': 0.0, 'cargo': 0.4733961820602417, 'total': 0.3295387402176857}, 'curr_20': {'habilidades': 0.4089803360402584, 'idiomas': 1.0, 'cargo': 0.5357565879821777, 'total': 0.6116414856165648}, 'curr_21': {'habilidades': 0.4697190076112747, 'idiomas': 1.0, 'cargo': 0.4733961820602417, 'total': 0.6295387402176857}, 'curr_22': {'habilidades': 0.3807860389351845, 'idiomas': 1.0, 'cargo': 0.45909440517425537, 'total': 0.5822119005024433}, 'curr_23': {'habilidades': 0.22559828124940395, 'idiomas': 1.0, 'cargo': 0.4522070586681366, 'total': 0.5032405523583293}, 'curr_24': {'habilidades': 0.24254637211561203, 'idiomas': 1.0, 'cargo': 0.40914157032966614, 'total': 0.5031015001237392}, 'curr_25': {'habilidades': 0.46507314406335354, 'idiomas': 0.0, 'cargo': 0.47156286239624023, 'total': 0.32684914451092484}, 'curr_26': {'habilidades': 0.24254637211561203, 'idiomas': 1.0, 'cargo': 0.40914157032966614, 'total': 0.5031015001237392}, 'curr_27': {'habilidades': 0.3439495414495468, 'idiomas': 0.0, 'cargo': 0.4358314871788025, 'total': 0.2591410681605339}, 'curr_28': {'habilidades': 0.46507314406335354, 'idiomas': 0.0, 'cargo': 0.47156286239624023, 'total': 0.32684914451092484}, 'curr_29': {'habilidades': 0.7328115403652191, 'idiomas': 0.5, 'cargo': 0.42307958006858826, 'total': 0.6010216861963272}, 'curr_30': {'habilidades': 0.4635408967733383, 'idiomas': 0.0, 'cargo': 0.4733961820602417, 'total': 0.3264496847987175}, 'curr_31': {'habilidades': 0.7328115403652191, 'idiomas': 0.0, 'cargo': 0.42307958006858826, 'total': 0.4510216861963272}, 'curr_32': {'habilidades': 0.22559828124940395, 'idiomas': 1.0, 'cargo': 0.4522070586681366, 'total': 0.5032405523583293}, 'curr_33': {'habilidades': 0.4089803360402584, 'idiomas': 0.5, 'cargo': 0.5357565879821777, 'total': 0.46164148561656476}, 'curr_34': {'habilidades': 0.5366339478641748, 'idiomas': 1.0, 'cargo': 0.42701438069343567, 'total': 0.6537198500707746}, 'curr_35': {'habilidades': 0.24254637211561203, 'idiomas': 0.0, 'cargo': 0.40914157032966614, 'total': 0.20310150012373923}, 'curr_36': {'habilidades': 0.3439495414495468, 'idiomas': 0.5, 'cargo': 0.4358314871788025, 'total': 0.4091410681605339}, 'curr_37': {'habilidades': 0.22559828124940395, 'idiomas': 1.0, 'cargo': 0.4522070586681366, 'total': 0.5032405523583293}, 'curr_38': {'habilidades': 0.24254637211561203, 'idiomas': 0.0, 'cargo': 0.40914157032966614, 'total': 0.20310150012373923}, 'curr_39': {'habilidades': 0.4697190076112747, 'idiomas': 0.0, 'cargo': 0.4733961820602417, 'total': 0.3295387402176857}, 'curr_40': {'habilidades': 0.46507314406335354, 'idiomas': 1.0, 'cargo': 0.47156286239624023, 'total': 0.6268491445109249}, 'curr_41': {'habilidades': 0.45761528983712196, 'idiomas': 0.0, 'cargo': 0.3662010729312897, 'total': 0.30204785950481894}, 'curr_42': {'habilidades': 0.33792024850845337, 'idiomas': 0.5, 'cargo': 0.3052271902561188, 'total': 0.38000556230545046}, 'curr_43': {'habilidades': 0.7328115403652191, 'idiomas': 0.5, 'cargo': 0.42307958006858826, 'total': 0.6010216861963272}, 'curr_44': {'habilidades': 0.42361604422330856, 'idiomas': 1.0, 'cargo': 0.8110970258712769, 'total': 0.6740274272859097}, 'curr_45': {'habilidades': 0.24254637211561203, 'idiomas': 1.0, 'cargo': 0.40914157032966614, 'total': 0.5031015001237392}, 'curr_46': {'habilidades': 0.4697190076112747, 'idiomas': 0.0, 'cargo': 0.4733961820602417, 'total': 0.3295387402176857}, 'curr_47': {'habilidades': 0.4089803360402584, 'idiomas': 0.0, 'cargo': 0.47505587339401245, 'total': 0.2995013426989317}, 'curr_48': {'habilidades': 0.40705761685967445, 'idiomas': 0.0, 'cargo': 0.3662010729312897, 'total': 0.2767690230160952}, 'curr_49': {'habilidades': 0.33792024850845337, 'idiomas': 0.0, 'cargo': 0.3052271902561188, 'total': 0.23000556230545044}, 'curr_50': {'habilidades': 0.4697190076112747, 'idiomas': 0.0, 'cargo': 0.4733961820602417, 'total': 0.3295387402176857}, 'curr_51': {'habilidades': 0.485828148201108, 'idiomas': 0.5, 'cargo': 0.4522070586681366, 'total': 0.4833554858341813}, 'curr_52': {'habilidades': 0.5565214157104492, 'idiomas': 1.0, 'cargo': 0.35022228956222534, 'total': 0.6483051657676697}, 'curr_53': {'habilidades': 0.34394950792193413, 'idiomas': 0.5, 'cargo': 0.4358314871788025, 'total': 0.4091410513967276}, 'curr_54': {'habilidades': 0.24254637211561203, 'idiomas': 0.0, 'cargo': 0.40914157032966614, 'total': 0.20310150012373923}, 'curr_55': {'habilidades': 0.7328115403652191, 'idiomas': 0.0, 'cargo': 0.42307958006858826, 'total': 0.4510216861963272}, 'curr_56': {'habilidades': 0.3807860389351845, 'idiomas': 1.0, 'cargo': 0.45909440517425537, 'total': 0.5822119005024433}, 'curr_57': {'habilidades': 0.42361604422330856, 'idiomas': 1.0, 'cargo': 0.8096780180931091, 'total': 0.6737436257302761}, 'curr_58': {'habilidades': 0.46507314406335354, 'idiomas': 1.0, 'cargo': 0.47156286239624023, 'total': 0.6268491445109249}, 'curr_59': {'habilidades': 0.5791685748845339, 'idiomas': 0.0, 'cargo': 0.5836670398712158, 'total': 0.4063176954165101}, 'curr_60': {'habilidades': 0.5366339478641748, 'idiomas': 0.0, 'cargo': 0.42701438069343567, 'total': 0.35371985007077456}, 'curr_61': {'habilidades': 0.4603424984961748, 'idiomas': 1.0, 'cargo': 0.5552329421043396, 'total': 0.6412178376689553}, 'curr_62': {'habilidades': 0.38878236897289753, 'idiomas': 1.0, 'cargo': 0.4358314871788025, 'total': 0.5815574819222092}, 'curr_63': {'habilidades': 0.5459728017449379, 'idiomas': 1.0, 'cargo': 0.0, 'total': 0.572986400872469}, 'curr_64': {'habilidades': 0.20947218127548695, 'idiomas': 1.0, 'cargo': 0.26594632863998413, 'total': 0.4579253563657403}, 'curr_65': {'habilidades': 0.5852803625166416, 'idiomas': 1.0, 'cargo': 0.2775558829307556, 'total': 0.648151357844472}, 'curr_66': {'habilidades': 0.5854405798017979, 'idiomas': 1.0, 'cargo': 0.1677938550710678, 'total': 0.6262790609151125}}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Top 3 melhores currículos para a vaga"
      ],
      "metadata": {
        "id": "cm0guVycej4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def top_3_curriculos():\n",
        "    pesos = {\n",
        "        \"habilidades\": 0.5,\n",
        "        \"idiomas\": 0.3,\n",
        "        \"cargo\": 0.2\n",
        "    }\n",
        "\n",
        "    curriculos_scores = {}\n",
        "    for cid, curriculo_analisado in curriculos_analisados.items():\n",
        "        scores = calcular_score_final(curriculo_analisado, input_rh, pesos, embedding_model)\n",
        "        curriculos_scores[cid] = scores\n",
        "\n",
        "    scores_ordenados = sorted(\n",
        "        curriculos_scores.items(),\n",
        "        key=lambda item: item[1]['total'],\n",
        "        reverse=True\n",
        "    )\n",
        "\n",
        "    top_curriculos = scores_ordenados[:3]\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\" ANÁLISE DOS MELHORES CANDIDATOS \".center(60))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    print(\"\\n Critérios de Busca Utilizados:\")\n",
        "    for criterio, valor in input_rh.items():\n",
        "        print(f\"  - {criterio.capitalize()}: {valor}\")\n",
        "\n",
        "    if not top_curriculos:\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(\"Nenhum currículo encontrado para ranquear.\".center(60))\n",
        "        print(\"=\"*60)\n",
        "        return\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"CLASSIFICAÇÃO FINAL\".center(60))\n",
        "    print(\"=\"*60)\n",
        "\n",
        "\n",
        "    for rank, (cid, score_info) in enumerate(top_curriculos, 1):\n",
        "\n",
        "        nome_arquivo = cid_arquivo_map.get(cid, \"Nome de arquivo não encontrado\")\n",
        "        dados_curriculo = curriculos_analisados.get(cid, {})\n",
        "\n",
        "        print(f\"\\n{rank}º LUGAR | Arquivo: {nome_arquivo}\")\n",
        "        print(\"-\" * 60)\n",
        "        print(f\" PONTUAÇÃO FINAL: {score_info['total']:.3f}\\n\")\n",
        "\n",
        "        print(\"  Breakdown da Pontuação:\")\n",
        "        print(f\"    - Habilidades: {score_info['habilidades']:.3f} (Peso: {pesos['habilidades']})\")\n",
        "        print(f\"    - Idiomas:     {score_info['idiomas']:.3f} (Peso: {pesos['idiomas']})\")\n",
        "        print(f\"    - Cargo:       {score_info['cargo']:.3f} (Peso: {pesos['cargo']})\")\n",
        "\n",
        "        print(\"\\n  Informações Relevantes do Currículo:\")\n",
        "        habilidades_encontradas = \", \".join(dados_curriculo.get('habilidades', ['N/A']))\n",
        "        idiomas_encontrados = \", \".join(dados_curriculo.get('idiomas', ['N/A']))\n",
        "        cargos_encontrados = \", \".join(dados_curriculo.get('cargo', ['N/A']))\n",
        "\n",
        "        print(f\"    - Habilidades: {habilidades_encontradas}\")\n",
        "        print(f\"    - Idiomas: {idiomas_encontrados}\")\n",
        "        print(f\"    - Cargo(s): {cargos_encontrados}\")\n",
        "\n",
        "        if rank < len(top_curriculos):\n",
        "             print(\"\\n\" + \"-\"*30)\n",
        "\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "\n",
        "top_3_curriculos()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4KuJO9gfEZF",
        "outputId": "b2db611e-aad5-41b3-9072-58ee366ba139"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "              ANÁLISE DOS MELHORES CANDIDATOS               \n",
            "============================================================\n",
            "\n",
            " Critérios de Busca Utilizados:\n",
            "  - Habilidades: Java,Spring,Docker,Scrum\n",
            "  - Idiomas: Português,Inglês\n",
            "  - Cargo: Desenvolvedor de Software Sênior\n",
            "\n",
            "============================================================\n",
            "                    CLASSIFICAÇÃO FINAL                     \n",
            "============================================================\n",
            "\n",
            "1º LUGAR | Arquivo: Mônica Gomes.pdf\n",
            "------------------------------------------------------------\n",
            " PONTUAÇÃO FINAL: 0.706\n",
            "\n",
            "  Breakdown da Pontuação:\n",
            "    - Habilidades: 0.579 (Peso: 0.5)\n",
            "    - Idiomas:     1.000 (Peso: 0.3)\n",
            "    - Cargo:       0.584 (Peso: 0.2)\n",
            "\n",
            "  Informações Relevantes do Currículo:\n",
            "    - Habilidades: Scrum, Kanban, JIRA\n",
            "    - Idiomas: Português, Inglês\n",
            "    - Cargo(s): Gerente de Projetos, Gerente de Projetos Junior\n",
            "\n",
            "------------------------------\n",
            "\n",
            "2º LUGAR | Arquivo: Yasmin Freitas.pdf\n",
            "------------------------------------------------------------\n",
            " PONTUAÇÃO FINAL: 0.674\n",
            "\n",
            "  Breakdown da Pontuação:\n",
            "    - Habilidades: 0.424 (Peso: 0.5)\n",
            "    - Idiomas:     1.000 (Peso: 0.3)\n",
            "    - Cargo:       0.811 (Peso: 0.2)\n",
            "\n",
            "  Informações Relevantes do Currículo:\n",
            "    - Habilidades: C#, .NET, Azure, SQL Server\n",
            "    - Idiomas: Português, Inglês\n",
            "    - Cargo(s): Engenheiro de Software\n",
            "\n",
            "------------------------------\n",
            "\n",
            "3º LUGAR | Arquivo: Ulisses Barros.pdf\n",
            "------------------------------------------------------------\n",
            " PONTUAÇÃO FINAL: 0.674\n",
            "\n",
            "  Breakdown da Pontuação:\n",
            "    - Habilidades: 0.424 (Peso: 0.5)\n",
            "    - Idiomas:     1.000 (Peso: 0.3)\n",
            "    - Cargo:       0.811 (Peso: 0.2)\n",
            "\n",
            "  Informações Relevantes do Currículo:\n",
            "    - Habilidades: C#, .NET, Azure, SQL Server\n",
            "    - Idiomas: Português, Inglês\n",
            "    - Cargo(s): Engenheiro de Software\n",
            "\n",
            "============================================================\n"
          ]
        }
      ]
    }
  ]
}